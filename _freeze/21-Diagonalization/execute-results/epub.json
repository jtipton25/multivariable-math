{
  "hash": "5528b389310fccc567ba50086e1fc5eb",
  "result": {
    "markdown": "# Diagonalization\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dasc2594)\nset.seed(2021)\n```\n:::\n\n\n\n\n::: {#def-}\nA $n \\times n$ matrix $\\mathbf{A}$ is **diagonalizable** if the matrix $\\mathbf{A}$ is similar to a diagonal matrix. This is equivalent to saying there exists some invertible $n \\times n$ matrix $\\mathbf{P}$ and diagonal matrix $\\mathbf{D}$ such that\n\n\n\n\n$$\n\\begin{aligned}\n\\mathbf{A} & = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}\n\\end{aligned}\n$$\n\n\n\n:::\n\n::: {#exm-}\nAny diagonal matrix $\\mathbf{D}$ is diagonalizable becuase it is self-similar.\n:::\n\n\n:::{#thm-diagonalization}\n## The Diagonalization Theorem\n\nA $n \\times n$ matrix $\\mathbf{A}$ is **diagonalizable** if and only if the matrix $\\mathbf{A}$ has $n$ linearly independent eigenvectors. \n\nIn addition, the $n \\times n$ matrix $\\mathbf{A} = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}$ with diagonal matrix $\\mathbf{D}$ if and only if the columns of $\\mathbf{P}$ are the lienarly independent eigenvectors of $\\mathbf{A}$. Then, the diagonal elements of $\\mathbf{D}$ are the eigenvalues of $\\mathbf{A}$ that correspond to the eigenvectors in $\\mathbf{P}$.\n\n:::\n\n::: {.callout-tip icon=false collapse=\"true\" appearance=\"simple\"} \n## Proof\n\nThis comes directly from @thm-distincteigenvalues where if a $n \\times n$ matrix has $n$ distinct eigenvalues $\\lambda_1 \\neq \\lambda_2 \\neq \\cdots \\neq \\lambda_n$, the the corresponding eigenvalues $\\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n$ are linearly independent.\n:::\n\nThis theorem implies that the matrix $\\mathbf{A}$ is diagonalizable if and only if the eigenvectors of $\\mathbf{A}$ form a basis for $\\mathcal{R}^n$. When this is the case, the set of eigenvectors is called an **eigenbasis**.\n\n::: {#exm-}\n\nConsider the following example of a diagonalizable matrix $\\mathbf{A}$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- matrix(c(9, 2, 0, -3, 2, -4, 1, 0, 3), 3, 3)\nA\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]    9   -3    1\n[2,]    2    2    0\n[3,]    0   -4    3\n```\n:::\n\n```{.r .cell-code}\neigen_A <- eigen(A)\nstr(eigen_A)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ values : num [1:3] 7.63 4.52 1.86\n $ vectors: num [1:3, 1:3] -0.905 -0.322 0.278 -0.407 -0.324 ...\n - attr(*, \"class\")= chr \"eigen\"\n```\n:::\n\n```{.r .cell-code}\nP <- eigen_A$vectors\nP\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           [,1]       [,2]        [,3]\n[1,] -0.9050468 -0.4069141 -0.01938647\n[2,] -0.3217259 -0.3235720  0.27433148\n[3,]  0.2781774  0.8542377  0.96143976\n```\n:::\n\n```{.r .cell-code}\nD <- diag(eigen_A$values)\nD\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         [,1]     [,2]     [,3]\n[1,] 7.626198 0.000000 0.000000\n[2,] 0.000000 4.515138 0.000000\n[3,] 0.000000 0.000000 1.858664\n```\n:::\n\n```{.r .cell-code}\nP %*% D %*% solve(P)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n             [,1] [,2]          [,3]\n[1,] 9.000000e+00   -3  1.000000e+00\n[2,] 2.000000e+00    2 -9.144832e-16\n[3,] 1.342835e-15   -4  3.000000e+00\n```\n:::\n\n```{.r .cell-code}\nall.equal(A, P %*% D %*% solve(P))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\n\n\n:::\n\n\n:::{#thm-}\nLet $\\mathbf{A}$ be a $n \\times n$ diagonalizable matrix with $\\mathbf{A} = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}$. Then, the matrix power $\\mathbf{A}^p$ is\n\n\n\n$$\n\\begin{aligned}\n\\mathbf{A}^p = \\mathbf{P} \\mathbf{D}^p \\mathbf{P}^{-1}\n\\end{aligned}\n$$\n\n\n\n:::\n\n::: {.callout-tip icon=false collapse=\"true\" appearance=\"simple\"} \n## Proof\n\nIn class\n:::\n\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n::: {#exm-}\nIn this example, we apply the diagonalization theorem to the matrix $\\mathbf{A}$ \n\nConsider the matrix $\\mathbf{A} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix}$ which has eigenvalues 1, 2, 3. Then the standard basis $\\mathbf{e}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$, $\\mathbf{e}_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$, and $\\mathbf{e}_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$ are corresponding eigenvectors (check the definition $\\mathbf{A} \\lambda = \\mathbf{v} \\lambda$) because \n\n\n\n\n$$\n\\begin{aligned}\n\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} & = 1 * \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} \\\\\n\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} & = 2 * \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} \\\\\n\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} & = 3 * \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} \n\\end{aligned}\n$$\n\n\n\nThus, by the diagonlaization theorem, we have $\\mathbf{A} = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}$ where $\\mathbf{P}$ is the identity matrix and $\\mathbf{D}$ is the diagonal matrix with entries 1, 2, 3. \n\n\n\n$$\n\\begin{aligned}\n\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} & = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}^{-1}\n\\end{aligned}\n$$\n\n\n\nwhich gives us that $\\mathbf{A}$ is similar to itself.\n\nHowever, there is nothing in the diagonalization theorem that says that we must put the eigenvalues in the order 1, 2, 3. If we put the eigenvalues in the order 3, 2, 1, then the corresponding eigenvectors are $\\mathbf{e}_3$, $\\mathbf{e}_2$, and $\\mathbf{e}_1$. Using the diagonlaization theorem, we have $\\mathbf{A} = \\tilde{\\mathbf{P}} \\tilde{\\mathbf{D}} \\tilde{\\mathbf{P}}^{-1}$ where $\\tilde{\\mathbf{P}}$ is the matrix with columns $\\mathbf{e}_3$, $\\mathbf{e}_2$, and $\\mathbf{e}_1$ and $\\tilde{\\mathbf{D}}$ is the diagonal matrix with entries 3, 2, 1 which results in \n\n\n\n$$\n\\begin{aligned}\n\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix} & = \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0 & 0 & 1 \\\\ 0 & 1 & 0 \\\\ 1 & 0 & 0 \\end{pmatrix}^{-1}\n\\end{aligned}\n$$\n\n\n\nwhich implies that the matrices $\\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 3 \\end{pmatrix}$ and $\\begin{pmatrix} 3 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & 1 \\end{pmatrix}$ are similar to each other\n\n:::\n",
    "supporting": [
      "21-Diagonalization_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": {},
    "postProcess": true
  }
}