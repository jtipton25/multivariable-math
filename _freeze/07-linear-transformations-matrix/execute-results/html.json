{
  "hash": "1a6f05cb5ed61fdf1bba11287222fb72",
  "result": {
    "markdown": "# Linear Transformations {#linear-transformations}\n\n- [3 Blue 1 Brown -- Linear transformations](https://www.3blue1brown.com/lessons/linear-transformations)\n\n- [3 Blue 1 Brown -- 3D transformations](https://www.3blue1brown.com/lessons/3d-transformations)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(dasc2594)\nlibrary(gifski)\n```\n:::\n\n::: {.cell}\n\n:::\n\n\nIt is often useful to think of $\\mathbf{A}\\mathbf{x}$ as a linear transformation defined by the matrix $\\mathbf{A}$ applied to the vector $\\mathbf{x}$.\n\nA linear transformation is mathematically defined as a function/mapping $T(\\cdot)$ ($T$ for transformation) from a **domain** in $\\mathcal{R}^n$ (function input) to a **codomain** in $\\mathcal{R}^m$ (function output). In shorthand, this is written as $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ which is read a \"$T$ maps inputs from the domain $\\mathcal{R}^n$ to the codomain $\\mathcal{R}^m$.\" For each $\\mathbf{x} \\in \\mathcal{R}^n$ (in the domain), $T(\\mathbf{x}) \\in \\mathcal{R}^m$ is known as the image of $\\mathbf{x}$. The set of all $T(\\mathbf{x})$ for all $\\mathbf{x} \\in \\mathcal{R}^n$ is known as the range of $T(\\mathbf{x})$. Note that it is possible that the range of $T(\\mathbf{x})$ is not required to be the entire space $\\mathcal{R}^m$ (i.e., the range of the transformation $T$ might be a subset of $\\mathcal{R}^m$)\n\n\n**Draw figure**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](./images/transformation-1.jpg){width=100%}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](./images/transformation-2.jpg){width=100%}\n:::\n:::\n\n\nIn the case of matrix transformations (linear transformations), the function $T(\\mathbf{x}) = \\mathbf{A} \\mathbf{x}$ where $\\mathbf{A}$ is a $m \\times n$ matrix and $\\mathbf{x} \\in \\mathcal{R}^n$ is a $n$-vector. \n\n* **Question:** What kind of object is $\\mathbf{A} \\mathbf{x}$?\n    * scalar\n    * vector\n    * matrix \n    * array\n\n* **Question** What are the dimensions of $\\mathbf{A} \\mathbf{x}$?\n\nUsing the matrix transformation notation, the domain of the transformation $T$ is $\\mathcal{R}^n$, the codomain of $\\mathcal{T}$ $\\mathcal{R}^m$. The range of the transformation $T$ is the set of all linear combinations of the columns of $\\mathbf{A}$ (the $\\mbox{span}\\{\\mathbf{a}_1, \\ldots, \\mathbf{a}_n\\}$) because the transformation $T(\\mathbf{x}) = \\mathbf{A} \\mathbf{x}$ is a linear combination $\\sum_{i=1}^n x_i \\mathbf{a}_i$ of the columns $\\{\\mathbf{a}_i\\}_{i=1}^n$ of $\\mathbf{A}$ with coefficients $x_1, \\ldots, x_n$\n\n\n::: {#exm-}\n\n$$\n\\begin{aligned}\n\\mathbf{A} = \\begin{pmatrix}\n2 & 4 \\\\\n-3 & 1 \\\\\n-1 & 6\n\\end{pmatrix}\n&& \\mathbf{u} = \\begin{pmatrix}\n1 \\\\\n3\n\\end{pmatrix}\n&& \\mathbf{b} = \\begin{pmatrix}\n-2 \\\\\n-11 \\\\\n-15\n\\end{pmatrix} &&\n\\mathbf{c} = \\begin{pmatrix}\n2 \\\\\n-2 \\\\\n-1\n\\end{pmatrix}\n\\end{aligned}\n$$\n\n::: {.cell}\n\n```{.r .cell-code}\nA <- matrix(c(2, -3, -1, 4, 1, 6), 3, 2)\nu <- c(1, 3)\nb <- 3 * A[, 1] - 2 * A[, 2]\nc <- c(2, -2, -1)\n```\n:::\n\n\n\na) Find the image of $\\mathbf{u}$ using the matrix transformation $T$ (e.g., calculate $T(\\mathbf{u})$).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# a\nA %*% u\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     [,1]\n[1,]   14\n[2,]    0\n[3,]   17\n```\n:::\n:::\n\n\nThe image of $\\mathbf{u}$ under $T$ is $T(\\mathbf{u}) = \\mathbf{A} \\mathbf{u} = \\begin{pmatrix} 14 \\\\ 0 \\\\ 17 \\end{pmatrix}$.\n\nb) Find a coefficient vector $\\mathbf{x} \\in \\mathcal{R}^2$ such that $T(\\mathbf{x}) = \\mathbf{b}$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#b\nrref(cbind(A, b))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          b\n[1,] 1 0  3\n[2,] 0 1 -2\n[3,] 0 0  0\n```\n:::\n:::\n\n\nA coefficient vector $\\mathbf{x}$ such that $T(\\mathbf{x}) = \\mathbf{b}$ is the solution to the matrix equation $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ which can be found from the reduced row echelon form of the augmented matrix above giving $\\mathbf{x} = \\begin{pmatrix} 3 \\\\ -2 \\end{pmatrix}$\n\nc) Is there more than one $\\mathbf{x}$ whose image under $T$ is $\\mathbf{b}?$ In other words, is the solution $\\mathbf{A} \\mathbf{x}= \\mathbf{b}$ unique?\n\nUse the reduced row echelon form of the matrix equation $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$ above which gives a unique solution as every (non augmented) column is a pivot. Thus, there is only one solution.\n\n\nd) Determine if $\\mathbf{c}$ is in the range of $T$. In other words, does the solution $\\mathbf{A} \\mathbf{x}= \\mathbf{c}$ exist?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# d\nrref(cbind(A, c)) # no because this is an inconsistent system of equations\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         c\n[1,] 1 0 0\n[2,] 0 1 0\n[3,] 0 0 1\n```\n:::\n:::\n\nThe solution to the matrix equation $\\mathbf{A} \\mathbf{x} = \\mathbf{c}$ which can be found from the reduced row echelon form of the augmented matrix above results in no solution because the last column (the augmented column) is a pivot column. Thus, the system of equations is inconsistent and $\\mathbf{c}$ cannot be written as a linear combination of the columns of $\\mathbf{A}$ which means that $\\mathbf{c}$ is not in the range of $T$. \n\n:::\n\n## Linear Transformations\n\n::: {#def-} \nA transformation $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is linear if\n\n1) $T(\\mathbf{u} + \\mathbf{v}) = T(\\mathbf{u}) + T(\\mathbf{v})$ for all $\\mathbf{u}$ and $\\mathbf{v}$ in the domain of $T$\n  \n2) $T(c \\mathbf{u}) = c T(\\mathbf{u})$ for all scalars $c$ and all vectors $\\mathbf{u}$ in the domain of $T$\n\n:::\n\nNote: Because a linear transformation is equivalent to a matrix transformation, the definition above is equivalent to the following matrix-vector multiplication properties\n\n\nIf $\\mathbf{A}$ is a $m \\times n$ matrix, $\\mathbf{u}$ and $\\mathbf{v}$ are vectors in $\\mathcal{R}^m$ and $c$ is a scalar, then\n\n1) $\\mathbf{A} (\\mathbf{u} + \\mathbf{v}) = \\mathbf{A} \\mathbf{u} + \\mathbf{A} \\mathbf{v}$\n2) $\\mathbf{A} (c \\mathbf{u}) = (c \\mathbf{A}) \\mathbf{u}$\n\nAs a consequence of the previous definition, the following properties hold for scalars $c$ and $d$ and vectors $\\mathbf{u}$ and $\\mathbf{v} \\in \\mathcal{R}^m$\n\n3) $T(\\mathbf{0}) = \\mathbf{0}$\n4) $T(c \\mathbf{u} + d \\mathbf{v}) = c T(\\mathbf{u}) + d T(\\mathbf{v})$\n\n* **Show why in class**\n\nThese properties give rise to the following statement for scalars $c_1, \\ldots, c_m$ and vectors $\\mathbf{u}_1, \\ldots, \\mathbf{u}_m \\in \\mathcal{R}^n$ \n\n5) $T(c_1 \\mathbf{u}_1 + \\ldots + c_m \\mathbf{u}_m) = c_1 T(\\mathbf{u}_1) + \\ldots + c_m T(\\mathbf{u}_m)$\n\n\n\nThe statements above for linear transformations are equivalent to the matrix statements where $\\mathbf{A}$ is a $m \\times n$ matrix, $\\mathbf{u}$ and $\\mathbf{v}$ are vectors in $\\mathcal{R}^m$ and $c$ is a scalar:\n\n3) $\\mathbf{A} \\mathbf{0} = \\mathbf{0}$\n4) $\\mathbf{A}(c \\mathbf{u} + d \\mathbf{v}) = c \\mathbf{A} \\mathbf{u} + d \\mathbf{A} \\mathbf{v}$\n\nAnd for a $m \\times n$ matrix $\\mathbf{A}$, scalars $c_1, \\ldots, c_m$, and vectors $\\mathbf{u}_1, \\ldots, \\mathbf{u}_m \\in \\mathcal{R}^n$\n\n5) $\\mathbf{A}(c_1 \\mathbf{u}_1 + \\ldots + c_m \\mathbf{u}_m) = c_1 \\mathbf{A}\\mathbf{u}_1 + \\ldots + c_m \\mathbf{A} \\mathbf{u}_m$\n\n\n## Types of matrix transformations\n\nThe basic types of matrix transformations include\n\n1) contractions/expansions\n2) rotations\n3) reflections\n4) shears\n5) projections\n\nFor the following examples, we will consider the unit vectors $\\mathbf{u} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{v} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$ and apply different linear transformations using the matrix $\\mathbf{A}$.\n\nTo build the matrix transformations, we use the `dasc2594` package and build matrix transformations based on code from [https://www.bryanshalloway.com/2020/02/20/visualizing-matrix-transformations-with-gganimate/](https://www.bryanshalloway.com/2020/02/20/visualizing-matrix-transformations-with-gganimate/). \n\n\n### Contractions/Expansions\n\n#### Horizonal Expansion\n\nThe matrix below gives a horizontal expansion when $x > 1$\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\nx & 0 \\\\\n0 & 1\n\\end{pmatrix}\n$$\n\n\n* In the example below, we set $x = 2$ and generate the transformation.\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/horizontal-expansion-matrix_77af5773856e894b18a110868336ae30'}\n\n```{.r .cell-code}\ntransformation_matrix <- tribble(\n  ~ x, ~ y,\n  2, 0,\n  0, 1) %>% \n  as.matrix()\n\np <- plot_transformation(transformation_matrix)\n```\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/horizontal-expansion-animation_50e2262b37a9e9bf8de65970ed6b8680'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/horizontal-expansion-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/horizontal-expansion-static-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Horizonal Contraction\n\nThe matrix below gives a horizontal contraction when $x < 1$\n* Horizontal contraction when $x < 1$\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\nx & 0 \\\\\n0 & 1\n\\end{pmatrix}\n$$\n\n\n* In the example below, we set $x = 0.5$\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/horizontal-contraction-matrix_044b43d505d8ec1eafea196e3f53839d'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/horizontal-contraction-animation_f46b5022d80e0187603200c667eafdc4'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/horizontal-contraction-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/horizontal-contraction-static-1.png){width=672}\n:::\n:::\n\n\n\n#### Vertical Expansion\n\nThe matrix below gives a vertical expansion when $x > 1$\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & x\n\\end{pmatrix}\n$$\n\n* In the example below, we set $x = 2$\n\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/vertical-expansion-matrix_0db113c0e086797279cc48e75c589b9b'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/vertical-expansion-animation_15f6c843182e273ec07c82ddaaadfe23'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/vertical-expansion-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/vertical-expansion-static-1.png){width=672}\n:::\n:::\n\n\n\n#### Vertical Contraction\n\nThe matrix below gives a vertical contraction when $x < 1$\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & x\n\\end{pmatrix}\n$$\n\n\n* In the example below, we set $x = 0.5$\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/vertical-contraction-matrix_ac3df6b4a3dc9bdb64ae85f83781b401'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/vertical-contraction-animation_2294d5e772448ff12a670c978b94855f'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/vertical-contraction-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/vertical-contraction-static-1.png){width=672}\n:::\n:::\n\n\n### Rotations\n\n#### Rotation by 90 degrees\n\nRotations in 2D of an angle $\\theta \\in [0, 2\\pi]$ take the form of \n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n\\cos(\\theta) & -\\sin(\\theta) \\\\\n\\sin(\\theta) & \\cos(\\theta)\n\\end{pmatrix}\n$$\n\nFor example, a rotation of 90 degrees counter-clockwise ($\\theta = \\frac{\\pi}{2}$) is given by the transformation matrix \n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n\\cos(\\frac{\\pi}{2}) & -\\sin(\\frac{\\pi}{2}) \\\\\n\\sin(\\frac{\\pi}{2}) & \\cos(\\frac{\\pi}{2})\n\\end{pmatrix} = \n\\begin{pmatrix}\n0 & -1 \\\\\n1 & 0\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/rotate-90-matrix_4f69c32fbea4d92c87497e27e7901442'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/rotate-90-animation_e5b916e00aee3235f051acc0ebbabeb3'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/rotate-90-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/rotate-90-static-1.png){width=672}\n:::\n:::\n\n\n\nAnother example is for a rotation of 45 degrees clockwise ($\\theta = -\\frac{\\pi}{4}$) is given by the transformation matrix \n\n$$\n = \\begin{pmatrix}\n\\cos(\\frac{\\pi}{4}) & -\\sin(\\frac{\\pi}{4}) \\\\\n\\sin(\\frac{\\pi}{4}) & \\cos(\\frac{\\pi}{4})\n\\end{pmatrix} = \n\\begin{pmatrix}\n\\frac{\\sqrt{2}}{2} & -\\frac{\\sqrt{2}}{2} \\\\\n\\frac{\\sqrt{2}}{2} & \\frac{\\sqrt{2}}{2}\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/rotate-45-matrix_53b389e112b3d151bb90cee3581305a9'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/rotate-45-animation_bbc10e647cbb7567fdb0b8868dc820d1'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/rotate-45-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/rotate-45-static-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Reflections\n\n#### Reflection across the x-axis\n\nThe matrix below gives a reflection about the x-axis\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & -1\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-x-axis-matrix_7b5fd79f85db1f0fa76ae01cbb265c8e'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-x-axis-animation_ffe14ad8da4289554fffa3bddf3466f7'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-x-axis-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-x-axis-1.png){width=672}\n:::\n:::\n\n\n\n#### Reflection across the y-axis\n\nThe matrix below gives a reflection about the y-axis\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n-1 & 0 \\\\\n0 & 1\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-y-axis-matrix_e8f5a861f50106218218e44cec49ba45'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-y-axis-animation_8f0e5041cbc9980c48b5d37e93520d07'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-y-axis-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-y-axis-static-1.png){width=672}\n:::\n:::\n\n\n#### Reflection across the line y = x\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n0 & 1 \\\\\n1 & 0\n\\end{pmatrix}\n$$\n\n\n* In the example below, we set $x = 0.5$\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-line-y-equals-x-matrix_78465d544877fcee1913a904ed1764dc'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-line-y-equals-x-animation_8f1ec265a632de96dcf39eca8cc54c5a'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-line-y-equals-x-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-line-y-equals-x-static-1.png){width=672}\n:::\n:::\n\n\n#### Reflection across the line y = - x\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n0 & -1 \\\\\n-1 & 0\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-line-y-equals-minus-x-matrix_5a404ab6c40f42bff209782bbb4a22b1'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-line-y-equals-minus-x-animation_bca7ab0db8176adcdff67c7522a4e558'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-line-y-equals-minus-x-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-line-y-equals-minus-x-static-1.png){width=672}\n:::\n:::\n\n\n\n#### Reflection across the origin (0, 0)\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n-1 & 0 \\\\\n0 & -1\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-origin-matrix_60119e94cb171e3f30d132ba4e0b8f67'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/reflection-origin-animation_aa23903f72bf39cf68ed8b95d8414793'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-origin-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/reflection-origin-static-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Shears\n\nA shear transformation is like stretching play-dough if it was possible to stretch all parts of the dough uniformly (rather than some sections getting stretched more than others).\n\n#### Horizontal Shear\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & x \\\\\n0 & 1\n\\end{pmatrix}\n$$\n\nFor the example below, we plot a horizontal shear with $x = 2$.\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/horizontal-shear-matrix_fc0226d3d6b7bd95a8aea29b46f7ff45'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/horizontal-shear-animation_541be71985978f594ff4774f403dc351'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/horizontal-shear-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/horizontal-shear-static-1.png){width=672}\n:::\n:::\n\n\n\n\n#### Vertical Shear\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 \\\\\nx & 1\n\\end{pmatrix}\n$$\n\nFor the example below, we plot a horizontal shear with $x = 2$.\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/vertical-shear-matrix_fa2e897122eeafc6307fa9751b69c524'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/vertical-shear-animation_b53af8941002f8546ba438ea69ff9940'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/vertical-shear-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/vertical-shear-static-1.png){width=672}\n:::\n:::\n\n\n\n\n\n### Projections\n\nA projection is a mapping $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^n$ from one space ($\\mathbf{R}^n$) to itself ($\\mathbf{R}^n$) such that $T^2 = T$\n\n#### Project onto the x-axis\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & 0\n\\end{pmatrix}\n$$\n\nFor the example below, we plot a projection onto the x-axis\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/projection-x-matrix_1205d8ca244229f7577c22f26db34a66'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/projection-x-animation_ce394f0c4a1ccb1543c1225ad8ff7443'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/projection-x-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/projection-x-static-1.png){width=672}\n:::\n:::\n\n\n#### Project onto the y-axis\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n0 & 0 \\\\\n0 & 1\n\\end{pmatrix}\n$$\n\nFor the example below, we plot a projection onto the y-axis\n\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/projection-y-matrix_bff33bb4a73298ad1652c28a8abc4955'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/projection-y-animation_ce3299e79c9c92c3722c09acb4c0fe67'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/projection-y-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/projection-y-static-1.png){width=672}\n:::\n:::\n\n\n\n\n### Identity\n\nThe identity transformation is the transformation that leaves the vector input unchanged. The identity matrix is typically written as $\\mathbf{I}$\n\n\n$$\n\\mathbf{I} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & 1\n\\end{pmatrix}\n$$\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/identity-matrix_51f4ec59d92de2a806217778a33b73f8'}\n\n:::\n\n::: {.cell hash='07-linear-transformations-matrix_cache/html/identity-animation_b2323d1cc4fbf2c83d3331cdec8914c3'}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/identity-animation-1.gif)\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](07-linear-transformations-matrix_files/figure-html/identity-static-1.png){width=672}\n:::\n:::\n\n\n\n## Properties of matrix transformations\n\n### One-to-one transformations\n\n::: {#def-} \n\nA transformation $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is called **one-to-one** if every vector $\\mathbf{b}$ in the image $\\mathcal{R}^m$, the equation $T(\\mathbf{x}) = \\mathbf{b}$ has **at most** one solution in $\\mathcal{R}^n$.\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/one-to-one.png){width=100%}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/not-one-to-one.png){width=100%}\n:::\n:::\n\n\n<!-- ```{r, echo=FALSE, engine='tikz', out.width='90%', fig.ext='png', fig.cap='One-to-one.'} -->\n\n<!-- \\begin{tikzpicture}[thin border nodes, scale=.75] -->\n<!--   \\draw[grid lines] (-3,-3) grid (3,3); -->\n\n<!--   \\node (A) at (0,-3.6) {$\\R^n$}; -->\n<!--   \\node (B) at (12,-3.6) {$\\R^m$}; -->\n<!--   \\draw[->] (A) -- (B) node[midway,above=1pt] {$T$}; -->\n\n<!--   \\point[\"$x$\" left] (x) at (1,1.5); -->\n<!--   \\point[\"$y$\" left] (y) at (-1,0); -->\n<!--   \\point[\"$z$\" left] (z) at (0,-2); -->\n\n<!--   \\begin{scope}[myxyz, xshift=12cm] -->\n<!--     \\path[clip, resetxy] (-3,-3) rectangle (3,3); -->\n\n<!--     \\def\\v{(-1,2,1)} -->\n<!--     \\def\\w{(0,1,-1)} -->\n\n<!--     \\node[coordinate] (X) at \\v {}; -->\n<!--     \\node[coordinate] (Y) at \\w {}; -->\n\n<!--     \\draw[very thin] (-2,0,0) -- (0,0,0); -->\n<!--     \\draw[very thin] (0,-2,0) -- (0,0,0); -->\n<!--     \\draw[very thin] (0,0,-2) -- (0,0,0); -->\n\n<!--     \\begin{scope}[x=(X), y=(Y), transformxy, -->\n<!--         every label/.style={font=\\small,fill=none,inner sep=.5pt}] -->\n<!--       \\fill[seq4!10, nearly opaque] (-1,-1) rectangle (1,1); -->\n<!--       \\draw[step=.5cm, seq4!30, very thin] (-1,-1) grid (1,1); -->\n<!--       \\point[\"$T(x)$\" above] (Tx) at (.5,-.5); -->\n<!--       \\point[\"$T(y)$\" above] (Ty) at (.5,.5); -->\n<!--       \\point[\"$T(z)$\" above] (Tz) at (-.5,.75); -->\n<!--       \\node[coordinate, -->\n<!--           pin={[pin edge={very thin,-}, -->\n<!--             pin distance=3mm,anchor=north,text=seq4]-70:range}] -->\n<!--         at (0.1,1) {}; -->\n<!--     \\end{scope} -->\n\n<!--     \\draw[->, very thin] (0,0,0) -- (2,0,0); -->\n<!--     \\draw[->, very thin] (0,0,0) -- (0,2,0); -->\n<!--     \\draw[->, very thin] (0,0,0) -- (0,0,2); -->\n\n<!--     \\draw[resetxy] (-3,-3) rectangle (3,3); -->\n\n<!--   \\end{scope} -->\n\n<!--   \\begin{scope}[arrows={|->}, shorten=.35mm, every to/.style={out=0, in=180}] -->\n<!--     \\draw (x) to (Tx); -->\n<!--     \\draw (y) to (Ty); -->\n<!--     \\draw (z) to (Tz); -->\n<!--   \\end{scope} -->\n\n<!--   \\node[seq-blue] at (6,2.5) {one-to-one}; -->\n\n<!-- \\end{tikzpicture} -->\n<!-- ``` -->\n\n\n\nThe following statements are equivalent was of saying $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is one-to-one:\n\na) For every $\\mathbf{b} \\in \\mathcal{R}^m$ (for every vector in the image), the equation $T(\\mathbf{x}) = \\mathbf{b}$ has either zero or one solution\n\nb) Every different input into the function $T(\\cdot)$ has a different output\n\nc) If $T(\\mathbf{u}) = T(\\mathbf{v})$ then $\\mathbf{u} = \\mathbf{v}$ \n\nThe following statements are equivalent was of saying $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is **not** one-to-one:\n\na) There exists as least one $\\mathbf{b} \\in \\mathcal{R}^m$ such that the equation $T(\\mathbf{x}) = \\mathbf{b}$ has more than one solution\n\nb) There are at least two  different inputs into the function $T(\\cdot)$ that have the same output\n\nc) There exist vectors $\\mathbf{u} \\neq \\mathbf{v} \\in \\mathcal{R}^n$ such that $T(\\mathbf{u}) = T(\\mathbf{v})$\n\n:::{#thm-}\nLet $\\mathbf{A}\\mathbf{x}$ be the matrix representation of the linear transformation $T(\\mathbf{x})$ for the $m \\times n$ matrix $\\mathbf{A}$. Then the following statements are equivalent:\n\n1) $T$ is one-to-one.\n\n2) For every $\\mathbf{b} \\in \\mathcal{R}^m$, the equation $T(\\mathbf{x}) = \\mathbf{b}$ has at most one solution.\n\n3) For every $\\mathbf{b} \\in \\mathcal{R}^m$, the equation $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ has a unique solution or is inconsistent.\n\n4) The equation $\\mathbf{A}\\mathbf{x} = \\mathbf{0}$ has only a trivial solution.\n\n5) The columns of $\\mathbf{A}$ are linearly independent.\n\n6) $\\mathbf{A}$ has a pivot in every column.\n\n7) The range of $\\mathbf{A}$ has dimension $n$\n\n:::\n\n* **Example:** is the following matrix one-to-one?\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 \\\\\n0 & 1 \\\\\n1 & 1\n\\end{pmatrix}\n$$\n\n\n* **Example:** is the following matrix one-to-one?\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n1 & 1 & 0\n\\end{pmatrix}\n$$\n\n\n**Note:** Matrices that are wider than they are tall are not one-to-one transformations. (This does not mean that all tall matrices are one-to-one)\n\n### Onto transformations\n\n::: {#def-}\n\nA transformation $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is called **onto** if, for every vector $\\mathbf{b} \\in \\mathcal{R}^m$, the equation $T(\\mathbf{x}) = \\mathbf{b}$ has **at least** one solution $\\mathbf{x} \\in \\mathcal{R}^n$\n\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/onto.png){width=100%}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](images/not-onto.png){width=100%}\n:::\n:::\n\n\n\nThe following are equivalent ways of saying that $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is onto:\n\n1) The range of $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is equal to the codomain of $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$\n\n2) Every vector in the codomain is the output of some input vector\n\n\nThe following are equivalent ways of saying that $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is not onto:\n\n1) The range of $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ is smaller than the codomain of $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$.\n\n2) There exists a vector $\\mathbf{b} \\in \\mathcal{R}^m$ such that the equation $T(\\mathbf{x})$ does not have a solution.\n\n3) There is a vector in the codomain that is not the output of any input vector.\n\n:::{#thm-} \nLet $\\mathbf{A}\\mathbf{x}$ be the matrix representation of the linear transformation $T(\\mathbf{x})$ for the $m \\times n$ matrix $\\mathbf{A}$. Then the following statements are equivalent:\n  \n1) $T$ is onto\n\n2) $T(\\mathbf{x}) = \\mathbf{b}$ has at least one solution for every $\\mathbf{b} \\in \\mathcal{R}^m$.\n\n3)  The equation $\\mathbf{A}\\mathbf{x} = \\mathbf{b}$ is consistent for every $\\mathbf{b} \\in \\mathcal{R}^m$.\n\n4) The columns of $\\mathbf{A}$ span $\\mathcal{R}^m$\n  \n6) $\\mathbf{A}$ has a pivot in every row\n\n7) The range of $T:\\mathcal{R}^n \\rightarrow \\mathcal{R}^m$ has dimension $m$\n\n:::\n\n\n* **Example:**\n\n* **Example:** is the following matrix onto?\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 1 & 0 \\\\\n0 & 1 & 1\n\\end{pmatrix}\n$$\n\n\n* **Example:** is the following matrix one-to-one?\n\n\n$$\n\\mathbf{A} = \\begin{pmatrix}\n1 & 0  \\\\\n0 & 1  \\\\\n1 & 0\n\\end{pmatrix}\n$$\n\n\n**Note:** Matrices that are taller than they are wide are not onto transformations. (This does not mean that all wide matrices are onto)\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}