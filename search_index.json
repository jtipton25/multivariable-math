[["index.html", "Multivariable Mathematics for Data Science Chapter 1 Preface 1.1 Outline", " Multivariable Mathematics for Data Science John Tipton 2020-12-23 Chapter 1 Preface This book will introduce students to multivariable Calculus and linear algebra methods and techniques to be successful in data science, statistics, computer science, and other data-driven, computational disciplines. The motiviation for this text is to provide both a theoretical understanding of important multivariable methods used in data science as well as giving a hands-on experience using software. Throughout this text, we assume the reader has a solid foundation in univariate calculus (typically two semesters) as well as familiarity with a scripting language (e.g., R or python). 1.1 Outline Introduction to vectors and matrices and vector and matrix operations vector spaces and subspaces dot products, cross products, projections linear combinations, linear independence, bases, coordinate systems planes, surfaces, and lines in space linear transformations, matrix arithmetic, and matrix rank solving linear equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) innner products, outer products, and norms projections - orthogonal projections and least squares matrix decompositoins: Eigen, Cholesky, principal components, singular value decomposition, pre-whitening matrix decompositoins: Eigen, Cholesky, principal components, singular value decomposition, pre-whitening limits, continuity, and partial derivatives chain rule, directional derivatives tangent planes, linear approximations, Taylor Series double/triple integrals, change of variables, Jacobian transformation double/triple integrals, change of variables, Jacobian transformation "],["section-vectors-and-matrices.html", "Chapter 2 Vectors and matrices 2.1 Vectors 2.2 Application in R 2.3 Exercises", " Chapter 2 Vectors and matrices Printing matrices to Latex in R array_to_LaTeX &lt;- function(arr){ rows &lt;- apply(arr, MARGIN=1, paste, collapse = &quot; &amp; &quot;) matrix_string &lt;- paste(rows, collapse = &quot; \\\\\\\\ &quot;) return(paste(&quot;\\\\begin{bmatrix}&quot;, matrix_string, &quot;\\\\end{bmatrix}&quot;)) } This can produce an error, so we wrap the function array_to_LaTeX in a call to cat() A &lt;- matrix(c(3,4,5,6,7,9,4,5,122), ncol=3, byrow=TRUE) array_to_LaTeX(A) [1] “\\begin{bmatrix} 3 &amp; 4 &amp; 5 \\\\ 6 &amp; 7 &amp; 9 \\\\ 4 &amp; 5 &amp; 122 \\end{bmatrix}” A &lt;- matrix(c(3,4,5,6,7,9,4,5,122), ncol=3, byrow=TRUE) cat(array_to_LaTeX(A)) \\[\\begin{bmatrix} 3 &amp; 4 &amp; 5 \\\\ 6 &amp; 7 &amp; 9 \\\\ 4 &amp; 5 &amp; 122 \\end{bmatrix}\\] The fundamental objects in this text are scalars, vectors, and matrices. 2.1 Vectors For notation, we let lowercase Roman letters represent scalar numbers (e.g., n = 5, d = 7), lowercase bold letters represent vectors \\[ \\begin{align*} \\textbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix}, \\end{align*} \\] where the elements \\(x_1, \\ldots, x_n\\) are scalars written in lowercase Roman. Note that vectors are assumed to follow a vertical notation where the elements of the vector (the \\(x_i\\)s are stacked on top of one another) and the order matters. For example, the vector \\[ \\begin{align*} \\mathbf{x} &amp; = \\begin{pmatrix} 5 \\\\ 2 \\\\ 8 \\end{pmatrix} \\end{align*} \\] has the first element \\(x_1 = 5\\), second element \\(x_2 = 2\\) and third element \\(x_3 = 8\\). Note that the vector \\(\\begin{pmatrix} 5 \\\\ 2 \\\\ 8 \\end{pmatrix}\\) is not the same as the vector \\(\\begin{pmatrix} 8 \\\\ 2 \\\\ 5 \\end{pmatrix}\\) because the order of the elements matters. We can also write the vector as \\[ \\begin{align*} \\textbf{x} = \\left( x_1, x_2, \\ldots, x_n \\right)&#39;, \\end{align*} \\] where the \\(&#39;\\) symbol represents the transpose function. For our example matrix, we have \\(\\begin{pmatrix} 5 \\\\ 2 \\\\ 8 \\end{pmatrix}&#39; = \\begin{pmatrix} 5 &amp; 2 &amp; 8 \\end{pmatrix}\\) which is the original vector but arranged in a row rather than a column. Likewise, the transpose of a row vector \\(\\begin{pmatrix} 5 &amp; 2 &amp; 8 \\end{pmatrix}&#39; = \\begin{pmatrix} 5 \\\\ 2 \\\\ 8 \\end{pmatrix}\\) is a column vector. If \\(\\mathbf{x}\\) is a column vector, we say that \\(\\mathbf{x}&#39;\\) is a row vector and if \\(\\mathbf{x}\\) is a row vector, the \\(\\mathbf{x}&#39;\\) is a column vector. 2.2 Application in R 2.2.1 Vectors To create a vector we can use the concatenate function c(). For example, the vector \\(\\mathbf{x} = \\begin{pmatrix} 5 \\\\ 2 \\\\ 8 \\end{pmatrix}\\) can be created as the R object using x &lt;- c(5, 2, 8) where the &lt;- assigns the values in the vector c(5, 2, 8) to the object named x. To print the values of x, we can use x ## [1] 5 2 8 which prints the elements of x. Notice that R prints the elements of \\(\\mathbf{x}\\) in a row; however, \\(\\mathbf{x}\\) is a column vector. This inconsistency is present to allow the output to be printed in a manner easier to read (more numbers fit on a row). If we put the column vector into a data.frame, then the vector will be presented as a column vector data.frame(x) ## x ## 1 5 ## 2 2 ## 3 8 One can use the index operator \\([\\hspace{2mm}]\\) to select specific elements of the vector \\(\\mathbf{x}\\). For example, the first element of \\(\\mathbf{x}\\), \\(x_1\\), is x[1] ## [1] 5 and the third element of \\(\\mathbf{x}\\), \\(x_3\\), is x[3] ## [1] 8 The transpose function t() turns a column vector into a row vector (or a row vector into a column vector). For example the transpose \\(\\mathbf{x}&#39;\\) of \\(\\mathbf{x}\\) is tx &lt;- t(x) tx ## [,1] [,2] [,3] ## [1,] 5 2 8 where tx is R object storing the transpose of \\(\\mathbf{x}\\) and is a row vector. The transpose of tx. Notice the indices on the output of the row vector tx. The index operator [1, ] selects the first row to tx and the index operator [, 1] gives the first column tx. Taking the transpose again gives us back the original column vector t(tx) ## [,1] ## [1,] 5 ## [2,] 2 ## [3,] 8 2.2.1.1 Properties of Vectors Scalar multiplication: For a scalar \\(a\\) and a vector \\(\\mathbf{x}\\), we have \\[ \\begin{align*} a \\mathbf{x} &amp; = a \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} a x_1 \\\\ a x_2 \\\\ \\vdots \\\\ a x_n \\end{pmatrix} \\end{align*} \\] where the scalar \\(a\\) is multiplied by each element of the vector. For example, \\[ \\begin{align*} 4 \\begin{pmatrix} 4 \\\\ 6 \\\\ 7 \\\\ 12 \\end{pmatrix} &amp; = \\begin{pmatrix} 4 * 4 \\\\ 4 * 6 \\\\ 4 * 7 \\\\ 4 * 12 \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} 16 \\\\ 24 \\\\ 28 \\\\ 48 \\end{pmatrix} \\end{align*} \\] In R, we can multiply the vector by a scalar as 4 * c(4, 6, 7, 12) ## [1] 16 24 28 48 or if the vector \\(\\mathbf{x} = \\left( 4, 6, 7, 12 \\right)&#39;\\) we can write this as x &lt;- c(4, 6, 7, 12) 4 * x ## [1] 16 24 28 48 For scalars \\(a\\) and \\(b\\) and a vector \\(\\mathbf{x}\\), we have \\[ \\begin{align*} a (b \\mathbf{x}) &amp; = (ab) \\mathbf{X} \\end{align*} \\] 4 * (6 * x) ## [1] 96 144 168 288 (4 * 6) * x ## [1] 96 144 168 288 For scalars \\(a\\) and \\(b\\) and a vector \\(\\mathbf{x}\\), we have \\[ \\begin{align*} a (b \\mathbf{x}) &amp; = (ab) \\mathbf{X} \\end{align*} \\] Vector Addition: Two vectors of length \\(n\\) can be added elementwise \\[ \\begin{align*} \\mathbf{x} + \\mathbf{y} &amp; = \\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix} + \\begin{pmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} x_1 + y_1 \\\\ x_2 + y_2 \\\\ \\vdots \\\\ x_n + y_n \\end{pmatrix} \\end{align*} \\] For example, \\[ \\begin{align*} \\begin{pmatrix} 3 \\\\ 1 \\\\ -4 \\\\ 3 \\end{pmatrix} + \\begin{pmatrix} -3 \\\\ 17 \\\\ -39 \\\\ 4 \\end{pmatrix} &amp; = \\begin{pmatrix} 3 + (-3) \\\\ 1 + 17 \\\\ -4 + (-39) \\\\ 3 + 4 \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} 0 \\\\ 18 \\\\ -43 \\\\ 7 \\end{pmatrix} \\end{align*} \\] In R, we have x &lt;- c(3, 1, -4, 3) y &lt;- c(-3, 17, -39, 4) x + y ## [1] 0 18 -43 7 If two vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) are of different lengths, then they cannot be added together. Using R, we get the following error: x &lt;- c(1, 2, 3) y &lt;- c(1, 2, 3, 4) x + y ## Warning in x + y: longer object length is not a multiple of shorter object ## length ## [1] 2 4 6 5 The error is telling us that the vector \\(\\mathbf{x}\\) and the vector \\(\\mathbf{y}\\) do not have the same length. Be careful when adding vectors in R. R uses “recycling” which means two vectors of different lengths can be added together if one vector is of a length that is a multiple of the other vector. For example, if \\(\\mathbf{x} = (1, 2)&#39;\\) is a vector of length 2 and \\(\\mathbf{y} = (1, 2, 3, 4)\\) is a vector of length 4, R will add \\(\\mathbf{x} + \\mathbf{y}\\) by replicating the vector \\(\\mathbf{x}\\) twice (i.e., \\(\\mathbf{x} + \\mathbf{y} = \\left( \\mathbf{x}&#39;, \\mathbf{x}&#39; \\right)&#39; = \\left(1, 2, 1, 2 \\right)&#39; + \\mathbf{y}\\)) x &lt;- c(1, 2) y &lt;- c(1, 2, 3, 4) x + y ## [1] 2 4 4 6 # replicated x = c(1, 2, 1, 2) c(1, 2, 1, 2) + y ## [1] 2 4 4 6 Associativity of Addition: For vectors \\(\\mathbf{x}\\), \\(\\mathbf{y}\\), and \\(\\mathbf{z}\\) all of equal length \\(n\\), we have \\[ \\begin{align*} (\\mathbf{x} + \\mathbf{y}) + \\mathbf{z} &amp; = \\mathbf{x} + (\\mathbf{y} + \\mathbf{z}) \\end{align*} \\] x &lt;- c(1, 2, 3, 4) y &lt;- c(4, 3, 5, 1) z &lt;- c(5, 2, 4, 6) (x + y) + z ## [1] 10 7 12 11 x + (y + z) ## [1] 10 7 12 11 Commutativity of Addition: For vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) of equal length \\(n\\), we have \\[ \\begin{align*} \\mathbf{x} + \\mathbf{y} &amp; = \\mathbf{y} + \\mathbf{x} \\end{align*} \\] x + y ## [1] 5 5 8 5 y + x ## [1] 5 5 8 5 Identity Element of Addition: For any vector \\(\\mathbf{x}\\) of length \\(n\\), there exists a vector \\(\\mathbf{0}\\), known as the zero vector, such that \\[ \\begin{align*} \\mathbf{x} + \\mathbf{0} &amp; = \\mathbf{x} \\end{align*} \\] x + 0 ## [1] 1 2 3 4 x + rep(0, 4) ## [1] 1 2 3 4 Inverse Element of Addition: For any vector \\(\\mathbf{x}\\) of length \\(n\\), there exists a vector \\(-\\mathbf{x}\\), known as the additive inverse vector, such that \\[ \\begin{align*} \\mathbf{x} + (- \\mathbf{x}) &amp; = \\mathbf{0} \\end{align*} \\] x + (-x) ## [1] 0 0 0 0 Transpose Transivity: The transpose operator is transitive \\[ \\begin{align*} (\\mathbf{x} + \\mathbf{y})&#39; &amp; = \\mathbf{x}&#39; + \\mathbf{y}&#39; \\end{align*} \\] t(x + y) ## [,1] [,2] [,3] [,4] ## [1,] 5 5 8 5 t(x) + t(y) ## [,1] [,2] [,3] [,4] ## [1,] 5 5 8 5 In addition, the transpose of a transpose is the identity operator \\(\\left( \\mathbf{x}&#39; \\right)&#39; = \\mathbf{x}\\). x ## [1] 1 2 3 4 t(x) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 t(t(x)) ## [,1] ## [1,] 1 ## [2,] 2 ## [3,] 3 ## [4,] 4 Note: R can be finicky about vectors and matrices. The transpose converts the vector \\(\\mathbf{x}\\) to a matrix \\(\\mathbf{x}&#39;\\) with one row. Thus, t(t(x)) gives a matrix with one column (which is a not quite the same as a vector). To force t(t(x)) to be a vector, you can drop the dimension with drop() drop(t(t(x))) ## [1] 1 2 3 4 2.2.2 Matrices We let uppercase bold letters \\(\\mathbf{A}\\), \\(\\mathbf{B}\\), etc., represent matrices. We define the matrix \\(\\mathbf{A}\\) with \\(n\\) rows and \\(p\\) columns as \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1p} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} &amp; a_{n2} &amp; \\cdots &amp; a_{np} \\end{pmatrix}, \\end{align*} \\] with \\(a_{ij}\\) being the value of the matrix \\(\\mathbf{A}\\) in the \\(i\\)th row and the \\(j\\)th column. If the matrix \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} 5 &amp; 7 &amp; 1 \\\\ 5 &amp; -22 &amp; 2 \\\\ -14 &amp; 5 &amp; 99 \\\\ 42 &amp; -3 &amp; 0\\end{pmatrix}, \\end{align*} \\] the elements \\(a_{11}\\) = 5, \\(a_{12}\\) = 7, \\(a_{21}\\) = 5, and \\(a_{33}\\) = 99, etc. In R, we can define the matrix A using the matrix() function A &lt;- matrix( data = c(5, 5, -14, 42, 7, -22, 5, -3, 1, 2, 99, 0), nrow = 4, ncol = 3 ) A ## [,1] [,2] [,3] ## [1,] 5 7 1 ## [2,] 5 -22 2 ## [3,] -14 5 99 ## [4,] 42 -3 0 Notice in the above creation of \\(\\mathbf{A}\\), we wrote defined the elements of the \\(\\mathbf{A}\\) using the columns stacked on top of one another. If we want to fill in the elements of \\(\\mathbf{A}\\) using the rows, we can add the option byrow = TRUE to the matrix() function A &lt;- matrix( data = c(5, 7, 1, 5, -22, 2, -14, 5, 99, 42, -3, 0), nrow = 4, ncol = 3, byrow = TRUE ) A ## [,1] [,2] [,3] ## [1,] 5 7 1 ## [2,] 5 -22 2 ## [3,] -14 5 99 ## [4,] 42 -3 0 To select the \\(ij\\)th elements of \\(\\mathbf{A}\\), we use the subset operator [ to select the element. For example, to get the element \\(a_{11} = 5\\) in the first row and first column of \\(\\mathbf{A}\\), we use A[1, 1] ## [1] 5 The element \\(a_{3, 3} = 99\\) in the third row and third column can be selected using A[3, 3] ## [1] 99 The matrix \\(\\mathbf{A}\\) can also be represented as a set of either column vectors \\(\\{\\mathbf{c}_j \\}_{j=1}^p\\) or row vectors \\(\\{\\mathbf{r}_i \\}_{i=1}^n\\). For example, the column vector representation is \\[ \\begin{align*} \\mathbf{A} &amp; = \\left( \\mathbf{c}_{1} \\middle| \\mathbf{c}_{2} \\middle| \\cdots \\middle| \\mathbf{c}_{p} \\right), \\end{align*} \\] where the notation \\(|\\) is used to separate the vectors \\[ \\begin{align*} \\mathbf{c}_1 &amp; = \\begin{pmatrix} a_{11} \\\\ a_{21} \\\\ \\vdots \\\\ a_{n1} \\end{pmatrix}, &amp; \\mathbf{c}_2 &amp; = \\begin{pmatrix} a_{12} \\\\ a_{22} \\\\ \\vdots \\\\ a_{n2} \\end{pmatrix}, &amp; \\cdots, &amp; &amp; \\mathbf{c}_p &amp; = \\begin{pmatrix} a_{1p} \\\\ a_{2p} \\\\ \\vdots \\\\ a_{np} \\end{pmatrix} \\end{align*} \\] In R you can extract the columns using the [ selection operator c1 &lt;- A[, 1] # first column c2 &lt;- A[, 2] # second column c3 &lt;- A[, 3] # third column and you can give the column representation of the matrix A with with column bind function cbind() cbind(c1, c2, c3) ## c1 c2 c3 ## [1,] 5 7 1 ## [2,] 5 -22 2 ## [3,] -14 5 99 ## [4,] 42 -3 0 The row vector representation of \\(\\mathbf{A}\\) is \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} \\mathbf{r}_{1} \\\\ \\mathbf{r}_{2} \\\\ \\vdots \\\\ \\mathbf{r}_{n} \\end{pmatrix}, \\end{align*} \\] where the row vectors \\(\\mathbf{r}_i\\) are \\[ \\begin{align*} \\mathbf{r}_1 &amp; = \\left( a_{11}, a_{21}, \\ldots, a_{n1} \\right) \\\\ \\mathbf{r}_2 &amp; = \\left( a_{12}, a_{22}, \\ldots, a_{n2} \\right) \\\\ &amp; \\vdots \\\\ \\mathbf{r}_n &amp; = \\left( a_{1p}, a_{2p}, \\ldots, a_{np} \\right) \\end{align*} \\] In R you can extract the rows using the [ selection operator r1 &lt;- A[1, ] # first row r2 &lt;- A[2, ] # second row r3 &lt;- A[3, ] # third row r4 &lt;- A[4, ] # fourth row and you can give the row representation of the matrix A with with row bind function rbind() rbind(r1, r2, r3, r4) ## [,1] [,2] [,3] ## r1 5 7 1 ## r2 5 -22 2 ## r3 -14 5 99 ## r4 42 -3 0 Another way to represent matrices is using a block form. A block-representation of a matrix arises when the \\(n \\times p\\) matrix \\(\\mathbf{A}\\) is represented using smaller blocks as follows: \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} \\mathbf{A}_{11} &amp; \\mathbf{A}_{12} &amp; \\cdots &amp; \\mathbf{A}_{1K} \\\\ \\mathbf{A}_{21} &amp; \\mathbf{A}_{22} &amp; \\cdots &amp; \\mathbf{A}_{2K} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\mathbf{A}_{J1} &amp; \\mathbf{A}_{J2} &amp; \\cdots &amp; \\mathbf{A}_{JK} \\\\ \\end{pmatrix} \\\\ \\end{align*} \\] where \\(\\mathbf{A}_{ij}\\) is a \\(n_j \\times p_k\\) matrix where \\(\\sum_{j=1}^J n_j = n\\) and \\(\\sum_{k=1}^K p_k = p\\). For example, the matrix \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} 5 &amp; 7 &amp; 1 \\\\ 5 &amp; -22 &amp; 2 \\\\ -14 &amp; 5 &amp; 99 \\\\ 42 &amp; -3 &amp; 0\\end{pmatrix}, \\end{align*} \\] can be written in block diagonal form with \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} \\mathbf{A}_{11} &amp; \\mathbf{A}_{12} \\\\ \\mathbf{A}_{21} &amp; \\mathbf{A}_{22} \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} \\begin{bmatrix} 5 &amp; 7 \\\\ 5 &amp; -22 \\end{bmatrix} &amp; \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} \\\\ \\begin{bmatrix} -14 &amp; 5 \\\\ 42 &amp; -3 \\end{bmatrix} &amp; \\begin{bmatrix} 99 \\\\ 0 \\end{bmatrix} \\end{pmatrix}, \\end{align*} \\] where \\(\\mathbf{A}_{11} = \\begin{bmatrix} 5 &amp; 7 \\\\ 5 &amp; -22 \\end{bmatrix}\\) is a \\(2 \\times 2\\) matrix, \\(\\mathbf{A}_{12} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}\\) is a \\(1 \\times 2\\) matrix, etc. A_11 &lt;- matrix(c(5, 5, 7, -22), 2, 2) A_12 &lt;- c(1, 2) A_21 &lt;- matrix(c(-14, 42, 5, -3), 2, 2) A_22 &lt;- c(99, 0) ## bind columns then rows rbind( cbind(A_11, A_12), cbind(A_21, A_22) ) ## A_12 ## [1,] 5 7 1 ## [2,] 5 -22 2 ## [3,] -14 5 99 ## [4,] 42 -3 0 ## bind rows then columns cbind( rbind(A_11, A_21), c(A_12, A_22) ## rbind on vectors is different than c() ) ## [,1] [,2] [,3] ## [1,] 5 7 1 ## [2,] 5 -22 2 ## [3,] -14 5 99 ## [4,] 42 -3 0 ## bind rows then columns cbind( rbind(A_11, A_21), ## convert the vectors to matrices for rbind rbind(as.matrix(A_12), as.matrix(A_22)) ) ## [,1] [,2] [,3] ## [1,] 5 7 1 ## [2,] 5 -22 2 ## [3,] -14 5 99 ## [4,] 42 -3 0 2.2.2.1 Properties of matrices Matrix Addition: If the matrices \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) are of the same dimension (e.g., both \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) have the same number of rows \\(n\\) and the same number of columns \\(p\\)), then \\[ \\begin{align*} \\mathbf{A} + \\mathbf{B} &amp; = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1p} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} &amp; a_{n2} &amp; \\cdots &amp; a_{np} \\end{pmatrix} + \\begin{pmatrix} b_{11} &amp; b_{12} &amp; \\cdots &amp; b_{1p} \\\\ b_{21} &amp; b_{22} &amp; \\cdots &amp; b_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{n1} &amp; b_{n2} &amp; \\cdots &amp; b_{np} \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} a_{11} + b_{11} &amp; b_{12} + b_{12} &amp; \\cdots &amp; a_{1p} + b_{1p} \\\\ a_{21} + b_{21} &amp; a_{22} + b_{22} &amp; \\cdots &amp; a_{2p} + b_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} + b_{n1} &amp; a_{n2} + b_{n2} &amp; \\cdots &amp; a_{np} + b_{np} \\end{pmatrix} \\\\ &amp; = \\left\\{ a_{ij} + b_{ij} \\right\\} \\end{align*} \\] … Another way to If \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) are of the same dimension (same number of rows and columns) you can add the matrices together A &lt;- matrix(c(4, 1, 33, 2, 0, -4), 3, 2) B &lt;- matrix(c(7, -24, 3, 9, 11, -9), 3, 2) A ## [,1] [,2] ## [1,] 4 2 ## [2,] 1 0 ## [3,] 33 -4 B ## [,1] [,2] ## [1,] 7 9 ## [2,] -24 11 ## [3,] 3 -9 A + B ## [,1] [,2] ## [1,] 11 11 ## [2,] -23 11 ## [3,] 36 -13 We can also write this using for loops # initialize an empty matrix to fill C &lt;- matrix(0, 3, 2) for (i in 1:nrow(A)) { # loop over the rows for (j in 1:ncol(A)) { # loop over the columns C[i, j] &lt;- A[i, j] + B[i, j] } } C ## [,1] [,2] ## [1,] 11 11 ## [2,] -23 11 ## [3,] 36 -13 If \\(\\mathbf{A}\\) and \\(\\mathbf{B}\\) are of different dimensions (they differ in either the number of rows or columns), R will return an error warning you that the matrices are of different sizes and can’t be added A &lt;- matrix(c(4, 1, 33, 2, 0, -4), 3, 2) B &lt;- matrix(c(7, -24, 3, 9), 2, 2) A ## [,1] [,2] ## [1,] 4 2 ## [2,] 1 0 ## [3,] 33 -4 B ## [,1] [,2] ## [1,] 7 3 ## [2,] -24 9 A + B ## Error in A + B: non-conformable arrays Matrix Multiplication: If \\(\\mathbf{A} = \\left\\{ a_{ij} \\right\\}\\) is an \\(n \\times p\\) matrix and \\(\\mathbf{B} = \\left\\{ a_{jk} \\right\\}\\) is a \\(p \\times q\\) matrix, then the matrix product \\(\\mathbf{C} = \\mathbf{A} \\mathbf{B}\\) is an \\(n \\times q\\) matrix where \\(\\mathbf{C} = \\left\\{ \\sum_{j=1}^p a_{ij} b{jk} \\right\\}\\) \\[ \\begin{align*} \\mathbf{A} \\mathbf{B} &amp; = \\begin{pmatrix} a_{11} &amp; a_{12} &amp; \\cdots &amp; a_{1p} \\\\ a_{21} &amp; a_{22} &amp; \\cdots &amp; a_{2p} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n1} &amp; a_{n2} &amp; \\cdots &amp; a_{np} \\end{pmatrix} \\begin{pmatrix} b_{11} &amp; b_{12} &amp; \\cdots &amp; b_{1q} \\\\ b_{21} &amp; b_{22} &amp; \\cdots &amp; b_{2q} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ b_{p1} &amp; b_{p2} &amp; \\cdots &amp; b_{pq} \\end{pmatrix} \\\\ &amp; = \\begin{pmatrix} \\sum_{j=1}^p a_{1j} b_{j1} &amp; \\sum_{j=1}^p a_{1j} b_{j2} &amp; \\cdots &amp; \\sum_{j=1}^p a_{1j} b_{jq} \\\\ \\sum_{j=1}^p a_{2j} b_{j1} &amp;\\sum_{j=1}^p a_{2j} b_{j2} &amp; \\cdots &amp; \\sum_{j=1}^p a_{2j} b_{jq} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\sum_{j=1}^p a_{nj} b_{j1} &amp;\\sum_{j=1}^p a_{nj} b_{j2} &amp; \\cdots &amp; \\sum_{j=1}^p a_{nj} b_{jq} \\end{pmatrix} \\\\ &amp; = \\left\\{ \\sum_{j=1}^p a_{ij} b_{jk} \\right\\} \\end{align*} \\] Another way to define matrix multiplication is through inner product notation. Define the \\(n \\times p\\) matrix \\(\\mathbf{A}\\) and the \\(p \\times q\\) matrix \\(\\mathbf{B}\\) as the partition \\[ \\begin{align*} \\mathbf{A} &amp; = \\begin{pmatrix} \\mathbf{a}_{1}&#39; \\\\ \\mathbf{a}_{2}&#39; \\\\ \\vdots \\\\ \\mathbf{a}_{n} \\end{pmatrix} &amp; \\mbox{ and } &amp;&amp; \\mathbf{B} &amp; = \\begin{pmatrix} \\mathbf{b}_{1} &amp; \\mathbf{b}_{2} &amp; \\cdots &amp; \\mathbf{b}_{p} \\end{pmatrix} \\end{align*} \\] where \\(\\mathbf{a}\\) and \\(\\mathbf{b}_k\\) are both \\(p\\)-vectors. Then, we have \\(\\mathbf{C} = \\mathbf{A} \\mathbf{B} = \\left\\{ c_{ik} \\right\\} = \\left\\{ \\mathbf{a}_i&#39; \\mathbf{b}_k \\right\\}\\) which has the matrix form \\[ \\begin{align*} \\mathbf{A} \\mathbf{B} &amp; = \\begin{pmatrix} \\mathbf{a}_1&#39; \\mathbf{b}_1 &amp; \\mathbf{a}_1&#39; \\mathbf{b}_2 &amp; \\cdots &amp; \\mathbf{a}_1&#39; \\mathbf{b}_q \\\\ \\mathbf{a}_2&#39; \\mathbf{b}_1 &amp; \\mathbf{a}_2&#39; \\mathbf{b}_2 &amp; \\cdots &amp; \\mathbf{a}_2&#39; \\mathbf{b}_q \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\mathbf{a}_n&#39; \\mathbf{b}_1 &amp; \\mathbf{a}_n&#39; \\mathbf{b}_2 &amp; \\cdots &amp; \\mathbf{a}_n&#39; \\mathbf{b}_q \\end{pmatrix} \\\\ &amp; = \\left\\{ \\mathbf{a}_i&#39; \\mathbf{b}_k \\right\\}. \\end{align*} \\] Written in this notation, we arrive at the multiplication rule for \\(\\mathbf{C} = \\mathbf{A} \\mathbf{B}\\) – the \\(ik\\)th element \\(c_{ik}\\) of \\(\\mathbf{C}\\) is the inner product of the \\(i\\)th row of \\(\\mathbf{A}\\) and the \\(j\\)th column of \\(\\mathbf{B}\\). Direct Sums: For the \\(n \\times p\\) matrix \\(\\mathbf{A}\\) and the \\(m \\times q\\) matrix \\(\\mathbf{B}\\), the direct sum is \\[ \\begin{align*} \\mathbf{C} &amp; = \\mathbf{A} \\bigoplus \\mathbf{B} \\\\ &amp; = \\begin{pmatrix} \\mathbf{A} &amp; \\mathbf{0}_{n \\times q} \\\\ \\mathbf{0}_{m \\times p} &amp; \\mathbf{B} \\end{pmatrix} \\\\ \\end{align*} \\] where \\(\\mathbf{0}_{n \\times q}\\) and \\(\\mathbf{0}_{m \\times p}\\) is an are \\(n \\times q\\) and \\(m \\times p\\) matrices of all 0s, respectively. The direct sum can be generalized to any arbitrary number of matrices as \\[ \\begin{align*} \\mathbf{C} &amp; = \\bigoplus_{i=1}^K \\mathbf{A}_i \\\\ &amp; = \\begin{pmatrix} \\mathbf{A}_1 &amp; \\mathbf{0} &amp; \\cdots &amp; \\mathbf{0} \\\\ \\mathbf{0} &amp; \\mathbf{A}_2 &amp; \\cdots &amp; \\mathbf{0} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\mathbf{0} &amp; \\mathbf{0} &amp; \\cdots &amp; \\mathbf{A}_K \\\\ \\end{pmatrix} \\\\ \\end{align*} \\] where the matrices \\(\\mathbf{0}\\) are all zeros of the appropriate dimension. 2.2.3 Arrays Higher order arrays (for example, tensors in the tensorflow library) can be represented using subscript notation where \\([\\mathbf{A}_1 | \\mathbf{A}_2 | \\cdots \\mathbf{A}_n]\\) is a 3-dimensional array. Higher order arrays can be represented using additional subscripts. 2.2.4 Lists To add: vector addition, multiplication To add: matrix addition, multiplication To add: determinants 2.3 Exercises What is 3 + \\(\\begin{pmatrix} 4 \\\\ 7 \\\\ 3 \\end{pmatrix}\\)? Why can’t you add the following two vectors: \\[ \\begin{align*} \\mathbf{x} = \\begin{pmatrix} 14 \\\\ 3 \\\\ 3 \\\\ -5 \\end{pmatrix} &amp; &amp; \\mathbf{y} = \\begin{pmatrix} 4 \\\\ 7 \\\\ 3 \\end{pmatrix} \\end{align*} \\] Based on the notation, what type of object is \\(\\mathbf{x}&#39;\\)? \\(\\mathbf{x}&#39; \\mathbf{y}\\)? \\(\\mathbf{x}&#39; \\mathbf{A}\\)? \\(\\mathbf{A}&#39; \\mathbf{y}\\)? \\(\\mathbf{X}&#39; \\mathbf{Z}\\)? "],["section-vector-spaces.html", "Chapter 3 Vectors spaces 3.1 Linear equations 3.2 Vector spaces in \\(\\mathcal{R}^n\\) 3.3 Linear Combinations of Vectors", " Chapter 3 Vectors spaces library(shiny) 3.1 Linear equations Let \\(x_1, x_2, \\ldots, x_n\\) be variables with coefficients \\(a_1, a_2, \\ldots, a_n\\), and \\(b\\) are fixed and known numbers. Then, we say \\[ \\begin{align} \\label{eq:linear} a_1 x_1 + a_2 x_2 + \\cdots + a_n x_n &amp; = b \\end{align} \\] is a linear equation. For example, the equation for a line with slope \\(m\\) and \\(y\\)-intercept \\(b\\) is \\[ \\begin{align*} y &amp; = m x + b, \\end{align*} \\] is a linear equation because it can be re-written as \\[ \\begin{align*} y - m x &amp; = b, \\end{align*} \\] where \\(a_1 = 1\\), \\(a_2 = m\\), \\(x_1 = y\\) and \\(x_2 = x\\). The equations \\[ \\begin{align*} \\sqrt{19} x_1 &amp; = (4 + \\sqrt{2}) x_2 - x_3 - 9 &amp; \\mbox{ and } &amp;&amp; -4 x_1 + 5 x_2 - 11 &amp; = x_3 \\end{align*} \\] are both linear equations because they can be written as \\[ \\begin{align*} \\sqrt{19} x_1 - (4 + \\sqrt{2}) x_2 + x_3 &amp; = - 9 &amp; \\mbox{ and } &amp;&amp; -4 x_1 + 5 x_2 - x_3 &amp; = 11, \\end{align*} \\] respectively. The equations \\[ \\begin{align*} x_1 &amp; = x_2^2 + 3 &amp; \\mbox{ and } &amp;&amp; x_1 + x_2 - x_1 x_2 &amp; = 16 \\end{align*} \\] are not linear equations because they do not meet the form of (The first equation above has a quadtric power of \\(x_2\\) and the second equation has a product of \\(x_1\\) and \\(x_2\\)). 3.1.1 Systems of linear equations A set of two or more linear equations that each contain the same set of variables is called a system of linear equations. The equations \\[ \\begin{align*} x_1 &amp;&amp; + &amp;&amp; 4 x_2 &amp;&amp; - &amp;&amp; x_3 &amp;&amp; = &amp; 11 \\\\ 4 x_1 &amp;&amp; + &amp;&amp; 5 x_2 &amp;&amp; &amp;&amp; &amp;&amp; = &amp; 9 \\end{align*} \\] are a system of equations. Note that in the second equation, the coefficient for \\(x_3\\) is 0, meaning we could re-write the above example as \\[ \\begin{align*} x_1 &amp;&amp; + &amp;&amp; 4 x_2 &amp;&amp; - &amp;&amp; x_3 &amp;&amp; = &amp; 11 \\\\ 4 x_1 &amp;&amp; + &amp;&amp; 5 x_2 &amp;&amp; + &amp;&amp; 0 x_3 &amp;&amp; = &amp; 9. \\end{align*} \\] 3.2 Vector spaces in \\(\\mathcal{R}^n\\) Let \\(\\mathcal{R}^n\\) be a real coordinate space of \\(n\\) dimesions. You are already familiar with the Cartesian plane that consists of ordered pairs \\((x, y)\\). The Cartesian plane defines the real coordinate space \\(\\mathbf{R}^2\\) of two dimensions. In \\(\\mathbf{R}^2\\), the location of any point of interest can be defined using the \\(x\\) and \\(y\\). For example, the plot below shows the location of the point (2, 3) dat &lt;- data.frame( x = 2, y = 3 ) ggplot(data = dat, aes(x = x, y = y)) + geom_point() + xlim(c(-4, 4)) + ylim(c(-4, 4)) A vector space is a generalization of this representation. In \\(\\mathcal{R}^2\\), we say that the vector \\(\\mathbf{z} = c(2, 3)\\) is centered at the origin (0, 0) and has length 2 in the \\(x\\)-axis and length 3 in the \\(y\\)-axis. The plot below shows this vector We can also decompose the vector \\(\\mathbf{z}\\) into its \\(x\\) and \\(y\\) components. The \\(x\\) component of \\(\\mathbf{z}\\) is (2, 0) and the \\(y\\) component of \\(\\mathbf{z}\\) is (0, 3). The following plot shows the \\(x\\) component (2, 0) in blue and the \\(y\\) component (0, 3) in red. The below Shiny app allows you to plot the vector for any \\((x, y)\\) pair of your choosing. The shiny app can be downloaded and run on your own computer using library(shiny) runGitHub(rep = &quot;multivariable-math&quot;, username = &quot;jtipton25&quot;, subdir = &quot;shiny-apps/chapter-03/vector-space&quot;) 3.3 Linear Combinations of Vectors We say that for any two scalars \\(a\\) and \\(b\\) and any two vectors \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) of length \\(n\\), the sum \\[ \\begin{align*} a \\mathbf{x} + b \\mathbf{y} &amp; = \\begin{pmatrix} a x_1 + b y_1 \\\\ a x_2 + b y_2 \\\\ \\vdots \\\\ a x_n + b y_n \\\\ \\end{pmatrix} \\end{align*} \\] is called a linear combination. The idea of a linear combination can be extended to \\(K\\) different scalars \\(\\{ a_1, \\ldots, a_K \\}\\) and \\(K\\) different vectors \\(\\{ \\mathbf{x}_1, \\ldots, \\mathbf{x}_K\\}\\) each of length \\(n\\) as \\[ \\begin{align*} \\sum_{k=1}^K a_k \\mathbf{x}_k &amp; = \\begin{pmatrix} \\sum_{k=1}^K a_k x_{k1} \\\\ \\sum_{k=1}^K a_k x_{k2} \\\\ \\vdots \\\\ \\sum_{k=1}^K a_k x_{kn} \\\\ \\end{pmatrix} \\end{align*} \\] "],["section-bases.html", "Chapter 4 Bases", " Chapter 4 Bases In this chapter, we introduce the fundamental concept of a basis. "],["section-planes-surfaces-and-lines-in-vector-spaces.html", "Chapter 5 Planes, Surfaces, and Lines in Vector spaces", " Chapter 5 Planes, Surfaces, and Lines in Vector spaces "],["section-linear-transformations-matrix-arithmetic-and-matrix-rank.html", "Chapter 6 Linear Transformations, Matrix Arithmetic, and Matrix Rank", " Chapter 6 Linear Transformations, Matrix Arithmetic, and Matrix Rank "],["section-solving-linear-equations-mathbfa-mathbfx-mathbfb.html", "Chapter 7 Solving linear equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\)", " Chapter 7 Solving linear equations \\(\\mathbf{A} \\mathbf{x} = \\mathbf{b}\\) "],["section-inner-products-and-norms.html", "Chapter 8 Inner Products and Norms", " Chapter 8 Inner Products and Norms "],["section-projections-orthogonal-projections-and-least-squares.html", "Chapter 9 Projections: Orthogonal Projections and Least Squares", " Chapter 9 Projections: Orthogonal Projections and Least Squares "],["section-matrix-decompositoins-eigen-singular-value-qr-and-cholesky.html", "Chapter 10 Matrix Decompositoins: Eigen, Singular Value, QR, and Cholesky", " Chapter 10 Matrix Decompositoins: Eigen, Singular Value, QR, and Cholesky "],["section-limits-continuity-and-partial-derivatives.html", "Chapter 11 Limits, Continuity, and Partial Derivatives", " Chapter 11 Limits, Continuity, and Partial Derivatives "],["section-matrix-calculus-gradients-the-chain-rule-directional-derivatives-and-tangent-planes.html", "Chapter 12 Matrix Calculus: Gradients, the Chain Rule, Directional Derivatives, and Tangent Planes", " Chapter 12 Matrix Calculus: Gradients, the Chain Rule, Directional Derivatives, and Tangent Planes "],["section-tangent-planes-and-taylor-linearization.html", "Chapter 13 Tangent Planes and Taylor Linearization", " Chapter 13 Tangent Planes and Taylor Linearization "],["section-double-and-triple-integrals-and-change-of-variables-jacobian.html", "Chapter 14 Double and Triple Integrals and Change of Variables (Jacobian)", " Chapter 14 Double and Triple Integrals and Change of Variables (Jacobian) "],["section-references.html", "References", " References "]]
