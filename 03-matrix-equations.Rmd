# Matrix equations {#matrix-equation}

Here we introduce the concept of the linear equation $\mathbf{A} \mathbf{x} = \mathbf{b}$. This equation is the most fundamental equation in all of statistics and data science. Given a matrix $\mathbf{A}$ and a vector of constants $\mathbf{b}$, the goal is to solve for the value (or values) of $\mathbf{x}$ that are a solution to this equation. The equation $\mathbf{A} \mathbf{x} = \mathbf{b}$ is a matrix representation of the system of linear equations

$$
\begin{align*}
\mathbf{A} \mathbf{x} & = \mathbf{b} \\
\begin{pmatrix} \mathbf{a}_1 & \ldots & \mathbf{a}_K \end{pmatrix} \begin{pmatrix} x_1 \\ \vdots \\ x_K \end{pmatrix} & = \mathbf{b} \\
x_1 \mathbf{a}_1 + \ldots + x_K \mathbf{a}_K & = \mathbf{b} \\
\end{align*}
$$

as long as the matrix $\mathbf{A}$ has $n$ rows and $K$ columns and the vectors $\mathbf{a}_k$ are $n$-dimensional.

* **Example: in class**

* **Example: in class**

## Solutions of matrix equations

Because the matrix equation $\mathbf{A} \mathbf{x} = \mathbf{b}$ is equivalent to a linear system of equations $x_1 \mathbf{a}_1 + \ldots + x_K \mathbf{a}_K = \mathbf{b}$, we can solve the matrix equation $\mathbf{A} \mathbf{x} = \mathbf{b}$ by writing the equation in an augmented matrix form
$$
\begin{align*}
\begin{pmatrix} \mathbf{a}_1 & \ldots & \mathbf{a}_K & \mathbf{b} \end{pmatrix}
\end{align*}
$$
and then reducing the matrix to reduced row echelon form. This gives rise to the theorem

**Theorem:** The matrix equation $\mathbf{A} \mathbf{x} = \mathbf{b}$, the vector equation $x_1 \mathbf{a}_1 + \ldots + x_K \mathbf{a}_K & = \mathbf{b}$, and the augmented matrix $\begin{pmatrix} \mathbf{a}_1 & \ldots & \mathbf{a}_K & \mathbf{b} \end{pmatrix}$ all have the same solution set.

## Existence of solutions
A solution to the matrix equation $\mathbf{A} \mathbf{x} = \mathbf{b}$ exists if and only if $\mathbf{b}$ is a linear combination of the columns of $\mathbf{A}$. In other words, $\mathbf{A} \mathbf{x} = \mathbf{b}$ has a solution if and only if $\mathbf{b}$ is in the $\mbox{span}\{\mathbf{a}_1, \ldots, \mathbf{a}_K\}$.

* **Example: in class** Let $\mathbf{A} =\ldots$ and $\mathbf{b} = \ldots$. Is the matrix equation $\mathbf{A} \mathbf{x} = \mathbf{b}$ consistent?

**Theorem:** For the $n \times K$ matrix $\mathbf{A}$, the following statements are equivalent:
a) For each $\mathbf{b} \in \mathcal{R}^K$, the equation $\mathbf{A} \mathbf{x} = \mathbf{b}$ has at least one solution
b) Each $\mathbf{b} \in \mathcal{R}^K$ is a linear combination of the columns of $\mathbf{A}$
c)  The columns of $\mathbf{A}$ span $\mathcal{R}^K$
d) $\mathbf{A}$ has a pivot in every row

## Matrix multiplication

To calculate $\mathbf{A} \mathbf{x}$, we need to define matrix multiplication. The equivalence between the linear systems of equations $x_1 \mathbf{a}_1 + \ldots + x_K \mathbf{a}_K = \mathbf{b}$ and the matrix equation $\mathbf{A} \mathbf{x}$ gives a hint in how to do this. First, recall the definition of $\mathbf{A}$ and $\mathbf{x}$

$$
\begin{align*}
\mathbf{A} = \begin{pmatrix}
a_{11} & a_{12} & \ldots & a_{1K} \\
a_{21} & a_{22} & \ldots & a_{2K} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \ldots & a_{nK} \\
\end{pmatrix} && \mathbf{x} = \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix}
\end{align*}
$$
The matrix product $\mathbf{A}\mathbf{x}$ is the linear system of equations
$$
\begin{align*}
\mathbf{A}  \mathbf{x} & = \begin{pmatrix}
a_{11} & a_{12} & \ldots & a_{1K} \\
a_{21} & a_{22} & \ldots & a_{2K} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & \ldots & a_{nK} \\
\end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ \vdots \\ x_n \end{pmatrix} \\
& = x_1\begin{pmatrix}
a_{11} \\ a_{21} \\ \vdots \\ a_{n1} 
\end{pmatrix} +
x_2 \begin{pmatrix}
a_{12} \\ a_{22} \\ \vdots \\ a_{n2} 
\end{pmatrix} +
\cdots + x_K \begin{pmatrix}
a_{1K} \\ a_{nK} \\ \vdots \\ a_{nK} \end{pmatrix} \\
& =  \begin{pmatrix}
a_{11} x_1 + a_{12} x_2 + \ldots + a_{1K} x_K \\
a_{21} x_1 + a_{22} x_2 + \ldots + a_{2K} x_K \\
\vdots \\
a_{n1} x_1 + a_{n2} x_2 + \ldots + a_{nK} x_K \\
\end{pmatrix}
\end{align*}
$$
Notice that the first row of the last matrix above has the sum first row of the matrix $\mathbf{A}$ multiplied by the corresponding elements in $\mathbf{x}$ (i.e., first element $a_{11}$ of the first row of $\mathbf{A}$ times the first element $x_1$ of $\mathbf{x}$ plus the second, third, fourth, etc.). Likewise, this pattern holds for the second row, and all the other rows. This gives an algorithm for evaluating the product $\mathbf{A} \mathbf{x}$.

**Definition:** The product $\mathbf{A}\mathbf{x}$ of a $n \times K$ matrix $\mathbf{A}$ with a $K$-vector $\mathbf{x}$ is a $n$-vector where the $i$th element of $\mathbf{A}\mathbf{x}$ is the sum of the $i$th row of $\mathbf{A}$ times the corresponding elements of the vector $\mathbf{x}$

* **Example: in class**

* **Example: in class**

* **Example: in R using loops**

* **Example: in R using `%*%`**

## Properties of matrix-vector multiplication

If $\mathbf{A}$ is a $n \times K$ matrix, $\mathbf{u}$ and $\mathbf{v}$ are vectors in $\mathcal{R}^K$ and $c$ is a scalar, then
a) $\mathbf{A} (\mathbf{u} + \mathbf{v}) = \mathbf{A} \mathbf{u} + \mathbf{A} + \mathbf{v}$
b) $\mathbf{A} (c \mathbf{u}) = (c \mathbf{A}) \mathbf{u}$

* **Proof in class**

## Solutions of linear systems

### Homogeneous linear systems of equations

**Definition:** The matrix equation $\mathbf{A}\mathbf{x} = \mathbf{0}$ is called a homogeneous system of equations. The vector $\mathbf{0}$ is a vector of length $K$ composed of all zeros. The **trivial** solution of the homogeneous equation is when $\mathbf{x} = \mathbf{0}$ and is not a very useful solution. Typically one is interested in **nontrivial** solutions where $\mathbf{x} \neq \mathbf{0}$.







