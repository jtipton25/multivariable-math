<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 23 Inner product, length, and orthogonality | Multivariable Mathematics for Data Science</title>
  <meta name="description" content="This is a text for Multivariable Mathematics for Data Science. This text is used at the University of Arkansas for the course DASC 2594 that exposes students to topics in linear algebra and vector calculus that are needed for success in data science. As such, a large focus of the text is on computation for these topics." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 23 Inner product, length, and orthogonality | Multivariable Mathematics for Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a text for Multivariable Mathematics for Data Science. This text is used at the University of Arkansas for the course DASC 2594 that exposes students to topics in linear algebra and vector calculus that are needed for success in data science. As such, a large focus of the text is on computation for these topics." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 23 Inner product, length, and orthogonality | Multivariable Mathematics for Data Science" />
  
  <meta name="twitter:description" content="This is a text for Multivariable Mathematics for Data Science. This text is used at the University of Arkansas for the course DASC 2594 that exposes students to topics in linear algebra and vector calculus that are needed for success in data science. As such, a large focus of the text is on computation for these topics." />
  

<meta name="author" content="John Tipton" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="diagonalization.html"/>
<link rel="next" href="graphs-and-limits.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.0/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Multivariable Mathematics for Data Science</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#getting-started-in-r"><i class="fa fa-check"></i><b>1.1</b> Getting started in <code>R</code></a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#some-videos-that-explain-useful-concepts-of-linear-algebra"><i class="fa fa-check"></i><b>1.2</b> Some videos that explain useful concepts of linear algebra</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#notation"><i class="fa fa-check"></i><b>1.3</b> Notation</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#matrices"><i class="fa fa-check"></i><b>1.3.1</b> Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html"><i class="fa fa-check"></i><b>2</b> Linear Systems of Equations</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#linear-systems-of-equations-1"><i class="fa fa-check"></i><b>2.1</b> Linear Systems of equations</a><ul>
<li class="chapter" data-level="2.1.1" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#linear-equations"><i class="fa fa-check"></i><b>2.1.1</b> Linear equations</a></li>
<li class="chapter" data-level="2.1.2" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#systems-of-linear-equations"><i class="fa fa-check"></i><b>2.1.2</b> Systems of linear equations</a></li>
<li class="chapter" data-level="2.1.3" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#solutions-of-linear-systems"><i class="fa fa-check"></i><b>2.1.3</b> Solutions of linear systems</a></li>
<li class="chapter" data-level="2.1.4" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#types-of-solutions"><i class="fa fa-check"></i><b>2.1.4</b> Types of solutions</a></li>
<li class="chapter" data-level="2.1.5" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#elementary-row-and-column-operations-on-matrices"><i class="fa fa-check"></i><b>2.1.5</b> Elementary row and column operations on matrices</a></li>
<li class="chapter" data-level="2.1.6" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#the-augmented-matrix-form-of-a-system-of-equations"><i class="fa fa-check"></i><b>2.1.6</b> The Augmented matrix form of a system of equations</a></li>
<li class="chapter" data-level="2.1.7" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#existence-and-uniqueness"><i class="fa fa-check"></i><b>2.1.7</b> Existence and Uniqueness</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#reduce-row-echelon-form"><i class="fa fa-check"></i><b>2.2</b> Reduce row echelon form</a><ul>
<li class="chapter" data-level="2.2.1" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#pivot-positions"><i class="fa fa-check"></i><b>2.2.1</b> Pivot positions</a></li>
<li class="chapter" data-level="2.2.2" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#finding-the-reduced-row-echelon-form"><i class="fa fa-check"></i><b>2.2.2</b> Finding the reduced row echelon form</a></li>
<li class="chapter" data-level="2.2.3" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#using-reduced-row-echelon-forms-to-solve-systems-of-linear-equations"><i class="fa fa-check"></i><b>2.2.3</b> Using reduced row echelon forms to solve systems of linear equations</a></li>
<li class="chapter" data-level="2.2.4" data-path="linear-systems-of-equations.html"><a href="linear-systems-of-equations.html#existence-and-uniqueness-from-reduced-row-echelon-form"><i class="fa fa-check"></i><b>2.2.4</b> Existence and uniqueness from reduced row echelon form</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="vector-spaces.html"><a href="vector-spaces.html"><i class="fa fa-check"></i><b>3</b> Vectors spaces</a><ul>
<li class="chapter" data-level="3.1" data-path="vector-spaces.html"><a href="vector-spaces.html#vectors"><i class="fa fa-check"></i><b>3.1</b> Vectors</a><ul>
<li class="chapter" data-level="3.1.1" data-path="vector-spaces.html"><a href="vector-spaces.html#properties-of-vectors"><i class="fa fa-check"></i><b>3.1.1</b> Properties of Vectors</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="vector-spaces.html"><a href="vector-spaces.html#vector-addition"><i class="fa fa-check"></i><b>3.2</b> Vector addition</a><ul>
<li class="chapter" data-level="3.2.1" data-path="vector-spaces.html"><a href="vector-spaces.html#the-geometric-interpretation-of-vectors-in-mathcalr2"><i class="fa fa-check"></i><b>3.2.1</b> The geometric interpretation of vectors in <span class="math inline">\(\mathcal{R}^2\)</span></a></li>
<li class="chapter" data-level="3.2.2" data-path="vector-spaces.html"><a href="vector-spaces.html#scalar-multiplication-of-vectors"><i class="fa fa-check"></i><b>3.2.2</b> Scalar multiplication of vectors</a></li>
<li class="chapter" data-level="3.2.3" data-path="vector-spaces.html"><a href="vector-spaces.html#the-geometric-interpretation-of-vectors-in-mathcalr3"><i class="fa fa-check"></i><b>3.2.3</b> The geometric interpretation of vectors in <span class="math inline">\(\mathcal{R}^3\)</span></a></li>
<li class="chapter" data-level="3.2.4" data-path="vector-spaces.html"><a href="vector-spaces.html#the-geometric-interpretation-of-vectors-in-mathcalrn"><i class="fa fa-check"></i><b>3.2.4</b> The geometric interpretation of vectors in <span class="math inline">\(\mathcal{R}^n\)</span></a></li>
<li class="chapter" data-level="3.2.5" data-path="vector-spaces.html"><a href="vector-spaces.html#linear-combinations-of-vectors"><i class="fa fa-check"></i><b>3.2.5</b> Linear Combinations of Vectors</a></li>
<li class="chapter" data-level="3.2.6" data-path="vector-spaces.html"><a href="vector-spaces.html#the-geometric-interpretation-of-linear-combinations-of-vectors"><i class="fa fa-check"></i><b>3.2.6</b> The geometric interpretation of linear combinations of vectors</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="vector-spaces.html"><a href="vector-spaces.html#span"><i class="fa fa-check"></i><b>3.3</b> Span</a><ul>
<li class="chapter" data-level="3.3.1" data-path="vector-spaces.html"><a href="vector-spaces.html#geometric-example-of-the-span"><i class="fa fa-check"></i><b>3.3.1</b> Geometric example of the span</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="matrix-equation.html"><a href="matrix-equation.html"><i class="fa fa-check"></i><b>4</b> Matrix equations</a><ul>
<li class="chapter" data-level="4.1" data-path="matrix-equation.html"><a href="matrix-equation.html#solutions-of-matrix-equations"><i class="fa fa-check"></i><b>4.1</b> Solutions of matrix equations</a></li>
<li class="chapter" data-level="4.2" data-path="matrix-equation.html"><a href="matrix-equation.html#existence-of-solutions"><i class="fa fa-check"></i><b>4.2</b> Existence of solutions</a></li>
<li class="chapter" data-level="4.3" data-path="matrix-equation.html"><a href="matrix-equation.html#matrix-vector-multiplication"><i class="fa fa-check"></i><b>4.3</b> Matrix-vector multiplication</a></li>
<li class="chapter" data-level="4.4" data-path="matrix-equation.html"><a href="matrix-equation.html#properties-of-matrix-vector-multiplication"><i class="fa fa-check"></i><b>4.4</b> Properties of matrix-vector multiplication</a></li>
<li class="chapter" data-level="4.5" data-path="matrix-equation.html"><a href="matrix-equation.html#solutions-of-linear-systems-1"><i class="fa fa-check"></i><b>4.5</b> Solutions of linear systems</a><ul>
<li class="chapter" data-level="4.5.1" data-path="matrix-equation.html"><a href="matrix-equation.html#homogeneous-linear-systems-of-equations"><i class="fa fa-check"></i><b>4.5.1</b> Homogeneous linear systems of equations</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="matrix-equation.html"><a href="matrix-equation.html#solutions-to-nonhomogeneous-systems"><i class="fa fa-check"></i><b>4.6</b> Solutions to nonhomogeneous systems</a></li>
<li class="chapter" data-level="4.7" data-path="matrix-equation.html"><a href="matrix-equation.html#finding-solutions"><i class="fa fa-check"></i><b>4.7</b> Finding solutions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="linear-independence.html"><a href="linear-independence.html"><i class="fa fa-check"></i><b>5</b> Linear independence</a></li>
<li class="chapter" data-level="6" data-path="linear-transformations.html"><a href="linear-transformations.html"><i class="fa fa-check"></i><b>6</b> Linear Transformations</a><ul>
<li class="chapter" data-level="6.1" data-path="linear-transformations.html"><a href="linear-transformations.html#linear-transformations-1"><i class="fa fa-check"></i><b>6.1</b> Linear Transformations</a></li>
<li class="chapter" data-level="6.2" data-path="linear-transformations.html"><a href="linear-transformations.html#types-of-matrix-transformations"><i class="fa fa-check"></i><b>6.2</b> Types of matrix transformations</a><ul>
<li class="chapter" data-level="6.2.1" data-path="linear-transformations.html"><a href="linear-transformations.html#contractionsexpansions"><i class="fa fa-check"></i><b>6.2.1</b> Contractions/Expansions</a></li>
<li class="chapter" data-level="6.2.2" data-path="linear-transformations.html"><a href="linear-transformations.html#rotations"><i class="fa fa-check"></i><b>6.2.2</b> Rotations</a></li>
<li class="chapter" data-level="6.2.3" data-path="linear-transformations.html"><a href="linear-transformations.html#reflections"><i class="fa fa-check"></i><b>6.2.3</b> Reflections</a></li>
<li class="chapter" data-level="6.2.4" data-path="linear-transformations.html"><a href="linear-transformations.html#shears"><i class="fa fa-check"></i><b>6.2.4</b> Shears</a></li>
<li class="chapter" data-level="6.2.5" data-path="linear-transformations.html"><a href="linear-transformations.html#projections"><i class="fa fa-check"></i><b>6.2.5</b> Projections</a></li>
<li class="chapter" data-level="6.2.6" data-path="linear-transformations.html"><a href="linear-transformations.html#identity"><i class="fa fa-check"></i><b>6.2.6</b> Identity</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="linear-transformations.html"><a href="linear-transformations.html#properties-of-matrix-transformations"><i class="fa fa-check"></i><b>6.3</b> Properties of matrix transformations</a><ul>
<li class="chapter" data-level="6.3.1" data-path="linear-transformations.html"><a href="linear-transformations.html#one-to-one-transformations"><i class="fa fa-check"></i><b>6.3.1</b> One-to-one transformations</a></li>
<li class="chapter" data-level="6.3.2" data-path="linear-transformations.html"><a href="linear-transformations.html#onto-transformations"><i class="fa fa-check"></i><b>6.3.2</b> Onto transformations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="matrix-operations.html"><a href="matrix-operations.html"><i class="fa fa-check"></i><b>7</b> Matrix operations</a><ul>
<li class="chapter" data-level="7.1" data-path="matrix-operations.html"><a href="matrix-operations.html#todo"><i class="fa fa-check"></i><b>7.1</b> ToDo</a></li>
<li class="chapter" data-level="7.2" data-path="matrix-operations.html"><a href="matrix-operations.html#properties-of-matrices"><i class="fa fa-check"></i><b>7.2</b> Properties of matrices</a><ul>
<li class="chapter" data-level="7.2.1" data-path="matrix-operations.html"><a href="matrix-operations.html#matrix-addition"><i class="fa fa-check"></i><b>7.2.1</b> Matrix Addition</a></li>
<li class="chapter" data-level="7.2.2" data-path="matrix-operations.html"><a href="matrix-operations.html#matrix-multipliation"><i class="fa fa-check"></i><b>7.2.2</b> Matrix Multipliation</a></li>
<li class="chapter" data-level="7.2.3" data-path="matrix-operations.html"><a href="matrix-operations.html#properties-of-matrix-multiplication"><i class="fa fa-check"></i><b>7.2.3</b> Properties of Matrix Multiplication</a></li>
<li class="chapter" data-level="7.2.4" data-path="matrix-operations.html"><a href="matrix-operations.html#matrix-multiplication-complexity-big-o-notation"><i class="fa fa-check"></i><b>7.2.4</b> Matrix Multiplication complexity (Big O notation)</a></li>
<li class="chapter" data-level="7.2.5" data-path="matrix-operations.html"><a href="matrix-operations.html#matrix-powers"><i class="fa fa-check"></i><b>7.2.5</b> Matrix powers</a></li>
<li class="chapter" data-level="7.2.6" data-path="matrix-operations.html"><a href="matrix-operations.html#matrix-transpose"><i class="fa fa-check"></i><b>7.2.6</b> Matrix Transpose</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="matrix-inverse.html"><a href="matrix-inverse.html"><i class="fa fa-check"></i><b>8</b> Matrix Inverses</a><ul>
<li class="chapter" data-level="8.1" data-path="matrix-inverse.html"><a href="matrix-inverse.html#elementary-matrices"><i class="fa fa-check"></i><b>8.1</b> Elementary matrices</a></li>
<li class="chapter" data-level="8.2" data-path="matrix-inverse.html"><a href="matrix-inverse.html#finding-the-inverse-of-mathbfa"><i class="fa fa-check"></i><b>8.2</b> Finding the inverse of <span class="math inline">\(\mathbf{A}\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="matrix-inverse.html"><a href="matrix-inverse.html#the-invertible-matrix-theorem"><i class="fa fa-check"></i><b>8.3</b> The Invertible Matrix Theorem</a></li>
<li class="chapter" data-level="8.4" data-path="matrix-inverse.html"><a href="matrix-inverse.html#invertible-linear-transformations"><i class="fa fa-check"></i><b>8.4</b> Invertible Linear Transformations</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="block-matrices.html"><a href="block-matrices.html"><i class="fa fa-check"></i><b>9</b> Block Matrices</a><ul>
<li class="chapter" data-level="9.1" data-path="block-matrices.html"><a href="block-matrices.html#block-matrix-addition"><i class="fa fa-check"></i><b>9.1</b> Block Matrix Addition</a></li>
<li class="chapter" data-level="9.2" data-path="block-matrices.html"><a href="block-matrices.html#block-matrix-multiplication"><i class="fa fa-check"></i><b>9.2</b> Block Matrix Multiplication</a></li>
<li class="chapter" data-level="9.3" data-path="block-matrices.html"><a href="block-matrices.html#the-column-row-matrix-product"><i class="fa fa-check"></i><b>9.3</b> The column-row matrix product</a></li>
<li class="chapter" data-level="9.4" data-path="block-matrices.html"><a href="block-matrices.html#special-block-matrices"><i class="fa fa-check"></i><b>9.4</b> Special Block Matrices</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="matrix-factorizations.html"><a href="matrix-factorizations.html"><i class="fa fa-check"></i><b>10</b> Matrix Factorizations</a><ul>
<li class="chapter" data-level="10.1" data-path="matrix-factorizations.html"><a href="matrix-factorizations.html#the-lu-factorization"><i class="fa fa-check"></i><b>10.1</b> The LU factorization</a><ul>
<li class="chapter" data-level="10.1.1" data-path="matrix-factorizations.html"><a href="matrix-factorizations.html#geometric-interpretation-of-the-lu-factorization"><i class="fa fa-check"></i><b>10.1.1</b> Geometric interpretation of the LU factorization</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="matrix-factorizations.html"><a href="matrix-factorizations.html#obtaining-the-lu-factorization"><i class="fa fa-check"></i><b>10.2</b> Obtaining the LU factorization</a></li>
<li class="chapter" data-level="10.3" data-path="matrix-factorizations.html"><a href="matrix-factorizations.html#the-cholesky-factor"><i class="fa fa-check"></i><b>10.3</b> The Cholesky factor</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="subspaces-Rn.html"><a href="subspaces-Rn.html"><i class="fa fa-check"></i><b>11</b> Subspaces of <span class="math inline">\(\mathcal{R}^n\)</span></a><ul>
<li class="chapter" data-level="11.1" data-path="subspaces-Rn.html"><a href="subspaces-Rn.html#special-subspaces-column-space-and-null-space"><i class="fa fa-check"></i><b>11.1</b> Special subspaces: column space and null space</a></li>
<li class="chapter" data-level="11.2" data-path="subspaces-Rn.html"><a href="subspaces-Rn.html#the-basis-of-a-subspace"><i class="fa fa-check"></i><b>11.2</b> The basis of a subspace</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="dimension-and-rank.html"><a href="dimension-and-rank.html"><i class="fa fa-check"></i><b>12</b> Dimension and Rank</a><ul>
<li class="chapter" data-level="12.1" data-path="dimension-and-rank.html"><a href="dimension-and-rank.html#coordinate-systems"><i class="fa fa-check"></i><b>12.1</b> Coordinate systems</a></li>
<li class="chapter" data-level="12.2" data-path="dimension-and-rank.html"><a href="dimension-and-rank.html#dimension-of-a-subspace"><i class="fa fa-check"></i><b>12.2</b> Dimension of a subspace</a></li>
<li class="chapter" data-level="12.3" data-path="dimension-and-rank.html"><a href="dimension-and-rank.html#rank"><i class="fa fa-check"></i><b>12.3</b> Rank</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="determinants.html"><a href="determinants.html"><i class="fa fa-check"></i><b>13</b> Determinants</a><ul>
<li class="chapter" data-level="13.1" data-path="determinants.html"><a href="determinants.html#determinants-of-2-times-2-matrices"><i class="fa fa-check"></i><b>13.1</b> Determinants of <span class="math inline">\(2 \times 2\)</span> matrices</a></li>
<li class="chapter" data-level="13.2" data-path="determinants.html"><a href="determinants.html#determinants-of-n-times-n-matrices"><i class="fa fa-check"></i><b>13.2</b> Determinants of <span class="math inline">\(n \times n\)</span> matrices</a></li>
<li class="chapter" data-level="13.3" data-path="determinants.html"><a href="determinants.html#properties-of-determinants"><i class="fa fa-check"></i><b>13.3</b> Properties of determinants</a></li>
<li class="chapter" data-level="13.4" data-path="determinants.html"><a href="determinants.html#cramers-rule-and-determinants"><i class="fa fa-check"></i><b>13.4</b> Cramer’s Rule and Determinants</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="determinants-and-volumes.html"><a href="determinants-and-volumes.html"><i class="fa fa-check"></i><b>14</b> Determinants and volumes</a><ul>
<li class="chapter" data-level="14.1" data-path="determinants-and-volumes.html"><a href="determinants-and-volumes.html#volumes-of-parallelpipeds"><i class="fa fa-check"></i><b>14.1</b> Volumes of Parallelpipeds</a></li>
<li class="chapter" data-level="14.2" data-path="determinants-and-volumes.html"><a href="determinants-and-volumes.html#volumes-of-linear-transformations"><i class="fa fa-check"></i><b>14.2</b> Volumes of Linear Transformations</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="vector-spaces-and-subspaces.html"><a href="vector-spaces-and-subspaces.html"><i class="fa fa-check"></i><b>15</b> Vector Spaces and Subspaces</a><ul>
<li class="chapter" data-level="15.1" data-path="vector-spaces-and-subspaces.html"><a href="vector-spaces-and-subspaces.html#null-space-and-column-space"><i class="fa fa-check"></i><b>15.1</b> Null space and column space</a><ul>
<li class="chapter" data-level="15.1.1" data-path="vector-spaces-and-subspaces.html"><a href="vector-spaces-and-subspaces.html#null-space"><i class="fa fa-check"></i><b>15.1.1</b> Null space</a></li>
<li class="chapter" data-level="15.1.2" data-path="vector-spaces-and-subspaces.html"><a href="vector-spaces-and-subspaces.html#column-space"><i class="fa fa-check"></i><b>15.1.2</b> Column space</a></li>
<li class="chapter" data-level="15.1.3" data-path="vector-spaces-and-subspaces.html"><a href="vector-spaces-and-subspaces.html#understanding-the-differerneces-between-the-column-space-and-the-null-space"><i class="fa fa-check"></i><b>15.1.3</b> Understanding the differerneces between the column space and the null space</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="linearly-independent-sets-and-bases.html"><a href="linearly-independent-sets-and-bases.html"><i class="fa fa-check"></i><b>16</b> Linearly independent sets and bases</a><ul>
<li class="chapter" data-level="16.1" data-path="linearly-independent-sets-and-bases.html"><a href="linearly-independent-sets-and-bases.html#bases-for-nullmathbfa-and-colmathbfa"><i class="fa fa-check"></i><b>16.1</b> Bases for null(<span class="math inline">\(\mathbf{A}\)</span>) and col(<span class="math inline">\(\mathbf{A}\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="coordinate-systems-and-dimension.html"><a href="coordinate-systems-and-dimension.html"><i class="fa fa-check"></i><b>17</b> Coordinate Systems and Dimension</a><ul>
<li class="chapter" data-level="17.1" data-path="coordinate-systems-and-dimension.html"><a href="coordinate-systems-and-dimension.html#coordinates-in-mathcalrn"><i class="fa fa-check"></i><b>17.1</b> Coordinates in <span class="math inline">\(\mathcal{R}^n\)</span></a></li>
<li class="chapter" data-level="17.2" data-path="coordinate-systems-and-dimension.html"><a href="coordinate-systems-and-dimension.html#dimension-of-a-vector-space"><i class="fa fa-check"></i><b>17.2</b> Dimension of a vector space</a></li>
<li class="chapter" data-level="17.3" data-path="coordinate-systems-and-dimension.html"><a href="coordinate-systems-and-dimension.html#subspaces-of-finite-dimension"><i class="fa fa-check"></i><b>17.3</b> Subspaces of finite dimension</a></li>
<li class="chapter" data-level="17.4" data-path="coordinate-systems-and-dimension.html"><a href="coordinate-systems-and-dimension.html#dimensions-of-nullmathbfa-and-colmathbfa"><i class="fa fa-check"></i><b>17.4</b> Dimensions of null(<span class="math inline">\(\mathbf{A}\)</span>) and col(<span class="math inline">\(\mathbf{A}\)</span>)</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="rank-1.html"><a href="rank-1.html"><i class="fa fa-check"></i><b>18</b> Rank</a><ul>
<li class="chapter" data-level="18.1" data-path="rank-1.html"><a href="rank-1.html#rank-2"><i class="fa fa-check"></i><b>18.1</b> Rank</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="change-of-basis.html"><a href="change-of-basis.html"><i class="fa fa-check"></i><b>19</b> Change of basis</a><ul>
<li class="chapter" data-level="19.1" data-path="change-of-basis.html"><a href="change-of-basis.html#changing-coordinates-between-different-bases"><i class="fa fa-check"></i><b>19.1</b> Changing coordinates between different bases</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="eigenvectors-and-eigenvalues.html"><a href="eigenvectors-and-eigenvalues.html"><i class="fa fa-check"></i><b>20</b> Eigenvectors and Eigenvalues</a><ul>
<li class="chapter" data-level="20.1" data-path="eigenvectors-and-eigenvalues.html"><a href="eigenvectors-and-eigenvalues.html#eigenspaces"><i class="fa fa-check"></i><b>20.1</b> Eigenspaces</a><ul>
<li class="chapter" data-level="20.1.1" data-path="eigenvectors-and-eigenvalues.html"><a href="eigenvectors-and-eigenvalues.html#computing-eigenspaces"><i class="fa fa-check"></i><b>20.1.1</b> Computing Eigenspaces</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="the-characteristic-equation.html"><a href="the-characteristic-equation.html"><i class="fa fa-check"></i><b>21</b> The Characteristic Equation</a><ul>
<li class="chapter" data-level="21.1" data-path="the-characteristic-equation.html"><a href="the-characteristic-equation.html#similarity"><i class="fa fa-check"></i><b>21.1</b> Similarity</a></li>
<li class="chapter" data-level="21.2" data-path="the-characteristic-equation.html"><a href="the-characteristic-equation.html#the-geometric-interpetation-of-similar-matrices"><i class="fa fa-check"></i><b>21.2</b> The geometric interpetation of similar matrices</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="diagonalization.html"><a href="diagonalization.html"><i class="fa fa-check"></i><b>22</b> Diagonalization</a></li>
<li class="chapter" data-level="23" data-path="inner-product-length-and-orthogonality.html"><a href="inner-product-length-and-orthogonality.html"><i class="fa fa-check"></i><b>23</b> Inner product, length, and orthogonality</a><ul>
<li class="chapter" data-level="23.1" data-path="inner-product-length-and-orthogonality.html"><a href="inner-product-length-and-orthogonality.html#distance"><i class="fa fa-check"></i><b>23.1</b> Distance</a></li>
<li class="chapter" data-level="23.2" data-path="inner-product-length-and-orthogonality.html"><a href="inner-product-length-and-orthogonality.html#orthogonal-vectors"><i class="fa fa-check"></i><b>23.2</b> Orthogonal vectors</a></li>
<li class="chapter" data-level="23.3" data-path="inner-product-length-and-orthogonality.html"><a href="inner-product-length-and-orthogonality.html#angles-between-vectors"><i class="fa fa-check"></i><b>23.3</b> Angles between vectors</a></li>
<li class="chapter" data-level="23.4" data-path="inner-product-length-and-orthogonality.html"><a href="inner-product-length-and-orthogonality.html#orthogonal-sets"><i class="fa fa-check"></i><b>23.4</b> Orthogonal sets</a></li>
<li class="chapter" data-level="23.5" data-path="inner-product-length-and-orthogonality.html"><a href="inner-product-length-and-orthogonality.html#orthogonal-projections"><i class="fa fa-check"></i><b>23.5</b> Orthogonal projections</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="graphs-and-limits.html"><a href="graphs-and-limits.html"><i class="fa fa-check"></i><b>24</b> Graphs and Limits</a><ul>
<li class="chapter" data-level="24.1" data-path="graphs-and-limits.html"><a href="graphs-and-limits.html#graphs-and-level-curves"><i class="fa fa-check"></i><b>24.1</b> Graphs and level curves</a></li>
<li class="chapter" data-level="24.2" data-path="graphs-and-limits.html"><a href="graphs-and-limits.html#limits"><i class="fa fa-check"></i><b>24.2</b> Limits</a><ul>
<li class="chapter" data-level="24.2.1" data-path="graphs-and-limits.html"><a href="graphs-and-limits.html#boundary-points"><i class="fa fa-check"></i><b>24.2.1</b> Boundary points</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="graphs-and-limits.html"><a href="graphs-and-limits.html#continuity"><i class="fa fa-check"></i><b>24.3</b> Continuity</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="partial-derivatives.html"><a href="partial-derivatives.html"><i class="fa fa-check"></i><b>25</b> Partial Derivatives</a><ul>
<li class="chapter" data-level="25.1" data-path="partial-derivatives.html"><a href="partial-derivatives.html#higher-order-partial-derivatives"><i class="fa fa-check"></i><b>25.1</b> Higher-order partial derivatives</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="the-chain-rule.html"><a href="the-chain-rule.html"><i class="fa fa-check"></i><b>26</b> The chain rule</a><ul>
<li class="chapter" data-level="26.1" data-path="the-chain-rule.html"><a href="the-chain-rule.html#the-chain-rule-with-one-independent-variable"><i class="fa fa-check"></i><b>26.1</b> The chain rule with one independent variable</a></li>
<li class="chapter" data-level="26.2" data-path="the-chain-rule.html"><a href="the-chain-rule.html#the-chain-rule-with-several-independent-variables"><i class="fa fa-check"></i><b>26.2</b> The chain rule with several independent variables</a></li>
<li class="chapter" data-level="26.3" data-path="the-chain-rule.html"><a href="the-chain-rule.html#the-chain-rule-in-matrix-notation"><i class="fa fa-check"></i><b>26.3</b> The chain rule in matrix notation</a></li>
</ul></li>
<li class="chapter" data-level="27" data-path="the-gradient-and-directional-derivatives.html"><a href="the-gradient-and-directional-derivatives.html"><i class="fa fa-check"></i><b>27</b> The gradient and directional derivatives</a><ul>
<li class="chapter" data-level="27.1" data-path="the-gradient-and-directional-derivatives.html"><a href="the-gradient-and-directional-derivatives.html#the-gradient"><i class="fa fa-check"></i><b>27.1</b> The Gradient</a><ul>
<li class="chapter" data-level="27.1.1" data-path="the-gradient-and-directional-derivatives.html"><a href="the-gradient-and-directional-derivatives.html#the-gradient-and-the-tangent-line"><i class="fa fa-check"></i><b>27.1.1</b> The gradient and the tangent line</a></li>
<li class="chapter" data-level="27.1.2" data-path="the-gradient-and-directional-derivatives.html"><a href="the-gradient-and-directional-derivatives.html#the-gradient-in-higher-dimensions"><i class="fa fa-check"></i><b>27.1.2</b> The gradient in higher dimensions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="tangent-planes-and-linear-approximations.html"><a href="tangent-planes-and-linear-approximations.html"><i class="fa fa-check"></i><b>28</b> Tangent planes and linear approximations</a></li>
<li class="chapter" data-level="29" data-path="minimums-and-maximums.html"><a href="minimums-and-maximums.html"><i class="fa fa-check"></i><b>29</b> Minimums and Maximums</a><ul>
<li class="chapter" data-level="29.1" data-path="minimums-and-maximums.html"><a href="minimums-and-maximums.html#local-minimums"><i class="fa fa-check"></i><b>29.1</b> Local minimums</a></li>
<li class="chapter" data-level="29.2" data-path="minimums-and-maximums.html"><a href="minimums-and-maximums.html#global-maximums-and-minimums"><i class="fa fa-check"></i><b>29.2</b> Global maximums and minimums</a></li>
<li class="chapter" data-level="29.3" data-path="minimums-and-maximums.html"><a href="minimums-and-maximums.html#grid-search-optimization"><i class="fa fa-check"></i><b>29.3</b> Grid search optimization</a></li>
<li class="chapter" data-level="29.4" data-path="minimums-and-maximums.html"><a href="minimums-and-maximums.html#gradient-descent"><i class="fa fa-check"></i><b>29.4</b> Gradient Descent</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Multivariable Mathematics for Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="inner-product-length-and-orthogonality" class="section level1">
<h1><span class="header-section-number">Chapter 23</span> Inner product, length, and orthogonality</h1>
<ul>
<li><a href="https://www.3blue1brown.com/lessons/dot-products">3 Blue 1 Brown – The dot prodcut</a></li>
</ul>
<div class="sourceCode" id="cb343"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb343-1"><a href="inner-product-length-and-orthogonality.html#cb343-1"></a><span class="kw">library</span>(tidyverse)</span>
<span id="cb343-2"><a href="inner-product-length-and-orthogonality.html#cb343-2"></a><span class="kw">library</span>(dasc2594)</span>
<span id="cb343-3"><a href="inner-product-length-and-orthogonality.html#cb343-3"></a><span class="kw">set.seed</span>(<span class="dv">2021</span>)</span></code></pre></div>
<div class="definition">
<p><span id="def:unlabeled-div-270" class="definition"><strong>Definition 23.1  </strong></span>Let <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> be vectors in <span class="math inline">\(\mathcal{R}^n\)</span>. Then, the <strong>inner product</strong> of <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> is <span class="math inline">\(\mathbf{u}&#39; \mathbf{v}\)</span>. The vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> are <span class="math inline">\(n \times 1\)</span> matrices where <span class="math inline">\(\mathbf{u}&#39;\)</span> is a <span class="math inline">\(1 \times n\)</span> matrix and the inner product <span class="math inline">\(\mathbf{u}&#39; \mathbf{v}\)</span> is a scalar (<span class="math inline">\(1 \times 1\)</span> matrix). The inner product is also sometimes called the dot product and written as <span class="math inline">\(\mathbf{u} \cdot \mathbf{v}\)</span>.</p>
<p>If the vectors
<span class="math display">\[
\begin{aligned}
\mathbf{u} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} &amp; &amp; \mathbf{v} = \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} 
\end{aligned}
\]</span>
then <span class="math inline">\(\mathbf{u}&#39; \mathbf{v} = u_1 v_1 + u_2 v_2 + \cdots u_n v_n\)</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-271" class="example"><strong>Example 23.1  </strong></span>Find the inner product <span class="math inline">\(\mathbf{u}&#39;\mathbf{v}\)</span> and <span class="math inline">\(\mathbf{v}&#39;\mathbf{u}\)</span> of
<span class="math display">\[
\begin{aligned}
\mathbf{u} = \begin{pmatrix} 2 \\ -3 \\ 1 \end{pmatrix} &amp; &amp; \mathbf{v} = \begin{pmatrix} 4 \\ -2 \\ 3 \end{pmatrix} 
\end{aligned}
\]</span></p>
<ul>
<li>do by hand</li>
</ul>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="inner-product-length-and-orthogonality.html#cb344-1"></a>u &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">-3</span>, <span class="dv">1</span>)</span>
<span id="cb344-2"><a href="inner-product-length-and-orthogonality.html#cb344-2"></a>v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">-2</span>, <span class="dv">3</span>)</span>
<span id="cb344-3"><a href="inner-product-length-and-orthogonality.html#cb344-3"></a><span class="co"># u&#39;v</span></span>
<span id="cb344-4"><a href="inner-product-length-and-orthogonality.html#cb344-4"></a><span class="kw">sum</span>(u<span class="op">*</span>v)</span></code></pre></div>
<pre><code>## [1] 17</code></pre>
<div class="sourceCode" id="cb346"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb346-1"><a href="inner-product-length-and-orthogonality.html#cb346-1"></a><span class="kw">t</span>(u) <span class="op">%*%</span><span class="st"> </span>v</span></code></pre></div>
<pre><code>##      [,1]
## [1,]   17</code></pre>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="inner-product-length-and-orthogonality.html#cb348-1"></a><span class="co"># v&#39;u</span></span>
<span id="cb348-2"><a href="inner-product-length-and-orthogonality.html#cb348-2"></a><span class="kw">sum</span>(v<span class="op">*</span>u)</span></code></pre></div>
<pre><code>## [1] 17</code></pre>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="inner-product-length-and-orthogonality.html#cb350-1"></a><span class="kw">t</span>(v) <span class="op">%*%</span><span class="st"> </span>u</span></code></pre></div>
<pre><code>##      [,1]
## [1,]   17</code></pre>
</div>
<p>The properties of inner products are defined with the following theorem.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-272" class="theorem"><strong>Theorem 23.1  </strong></span>Let <span class="math inline">\(\mathbf{u}\)</span>, <span class="math inline">\(\mathbf{v}\)</span>, and <span class="math inline">\(\mathbf{w}\)</span> be vectors in <span class="math inline">\(\mathcal{R}^n\)</span> and let <span class="math inline">\(c\)</span> be a scalar. Then</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(\mathbf{u}&#39;\mathbf{v} = \mathbf{v}&#39;\mathbf{u}\)</span></p></li>
<li><p><span class="math inline">\((\mathbf{u} + \mathbf{v})&#39; \mathbf{w} = \mathbf{u}&#39; \mathbf{w} + \mathbf{v}&#39; \mathbf{w}\)</span></p></li>
<li><p><span class="math inline">\(( c \mathbf{u} )&#39; \mathbf{v} = c ( \mathbf{v}&#39;\mathbf{u} )\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{u}&#39;\mathbf{u} \geq 0\)</span> with <span class="math inline">\(\mathbf{u}&#39;\mathbf{u} = 0\)</span> only when <span class="math inline">\(\mathbf{u} = \mathbf{0}\)</span></p></li>
</ol>
</div>
<p>Based on the theorem above, the inner product of a vector with itself (<span class="math inline">\(\mathbf{u}&#39;\mathbf{u}\)</span>) is strictly non-negative. Thus, we can define the length of the vector <span class="math inline">\(\mathbf{u}\)</span> (also called the <strong>norm</strong> of the vector <span class="math inline">\(\mathbf{u}\)</span>).</p>
<div class="definition">
<p><span id="def:unlabeled-div-273" class="definition"><strong>Definition 23.2  </strong></span>The length of a vector <span class="math inline">\(\mathbf{v} \in \mathcal{R}^n\)</span>, also called the vector <strong>norm</strong> <span class="math inline">\(\| \mathbf{v} \|\)</span> is defined as
<span class="math display">\[
\begin{aligned}
\| \mathbf{v} \| &amp; = \sqrt{\mathbf{v}&#39;\mathbf{v}} = \sqrt{v_1^2 + v_2^2 + \cdots + v_n^2}
\end{aligned}
\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-274" class="example"><strong>Example 23.2  </strong></span>Let <span class="math inline">\(\mathbf{v} = \begin{pmatrix} a \\ b \end{pmatrix} \in \mathcal{R}^2\)</span>. Show that the definition of the norm satisfies the Pythagorean theorem.</p>
</div>
<p>Another property of the norm is how the norm changes based on scalar multiplication. Let <span class="math inline">\(\mathbf{v} \in \mathcal{R}^n\)</span> be a vector and let <span class="math inline">\(c\)</span> be a scalar. Then <span class="math inline">\(\|c \mathbf{v}\| = |c|\|\mathbf{v}\|\)</span></p>
<div class="definition">
<p><span id="def:unlabeled-div-275" class="definition"><strong>Definition 23.3  </strong></span>A vector <span class="math inline">\(\mathbf{v} \in \mathcal{R}^n\)</span> whose length/norm is 1 is called a <strong>unit</strong> vector. Any vector can be made into a unit vector through <strong>normalization</strong> by multiplying the vector <span class="math inline">\(\mathbf{v}\)</span> by <span class="math inline">\(\frac{1}{\|\mathbf{v}\|}\)</span> to get a unit vector <span class="math inline">\(\mathbf{u} = \frac{\mathbf{v}}{\|\mathbf{v}\|}\)</span> in the same direction as <span class="math inline">\(\mathbf{v}\)</span>.</p>
</div>
<div id="distance" class="section level2">
<h2><span class="header-section-number">23.1</span> Distance</h2>
<p>In two dimensions, the Euclidean distance between the points <span class="math inline">\((x_1, y_1)\)</span> and <span class="math inline">\((x_2, y_2)\)</span> is defined as <span class="math inline">\(\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}\)</span>. In higher dimensions, a similar definition holds.</p>
<div class="definition">
<p><span id="def:unlabeled-div-276" class="definition"><strong>Definition 23.4  </strong></span>Let <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> be vectors in <span class="math inline">\(\mathcal{R}^n\)</span>. Then the distance <span class="math inline">\(dist(\mathbf{u}, \mathbf{v})\)</span> between <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> is</p>
<p><span class="math display">\[
\begin{aligned}
dist(\mathbf{u}, \mathbf{v}) = \|\mathbf{u} - \mathbf{v}\|
\end{aligned}
\]</span></p>
</div>
<div class="example">
<p><span id="exm:unlabeled-div-277" class="example"><strong>Example 23.3  </strong></span>Distance between two 3-dimensional vectors</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="inner-product-length-and-orthogonality.html#cb352-1"></a>u &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">-5</span>, <span class="dv">1</span>)</span>
<span id="cb352-2"><a href="inner-product-length-and-orthogonality.html#cb352-2"></a>v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">-2</span>)</span>
<span id="cb352-3"><a href="inner-product-length-and-orthogonality.html#cb352-3"></a><span class="kw">sqrt</span>(<span class="kw">sum</span>((u<span class="op">-</span>v)<span class="op">^</span><span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 8.602325</code></pre>
</div>
</div>
<div id="orthogonal-vectors" class="section level2">
<h2><span class="header-section-number">23.2</span> Orthogonal vectors</h2>
<p>The equivalent of perpendicular lines in <span class="math inline">\(\mathcal{R}^n\)</span> are known as orthogonal vectors.
<!-- Geometrically, two vectors are defined as orthogonal if the distance between $\mathbf{u}$ and $\mathbf{v}$ is the same as the distance between $\mathbf{u}$ and $-\mathbf{v}$. **Draw picture -- perpendicular triangle** -->
<!-- $$\begin{aligned} -->
<!-- dist(\mathbf{u}, - \mathbf{v}) & =  -->
<!-- \end{aligned}$$ --></p>
<div class="definition">
<p><span id="def:unlabeled-div-278" class="definition"><strong>Definition 23.5  </strong></span>The two vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> in <span class="math inline">\(\mathcal{R}^n\)</span> are orthogonal if
<span class="math display">\[
\begin{aligned}
\mathbf{u}&#39; \mathbf{v} = 0
\end{aligned}
\]</span></p>
</div>
</div>
<div id="angles-between-vectors" class="section level2">
<h2><span class="header-section-number">23.3</span> Angles between vectors</h2>
<p>Let <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> be vectors <span class="math inline">\(\mathcal{R}^n\)</span>. Then, the angle between the vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> is defined as the angle <span class="math inline">\(\theta\)</span> in the relationship
<span class="math display">\[
\begin{aligned}
\mathbf{u}&#39; \mathbf{v} = \| \mathbf{u} \| \| \mathbf{v} \| cos(\theta)
\end{aligned}
\]</span>
Solving for the angle <span class="math inline">\(\theta\)</span> results in the equation
<span class="math display">\[
\begin{aligned}
\theta = arccos \left( \frac{\mathbf{u}&#39; \mathbf{v}}{\| \mathbf{u} \| \| \mathbf{v} \|} \right)
\end{aligned}
\]</span>
where <span class="math inline">\(arccos(\cdot)\)</span> is inverse cosine function, which is <code>acos()</code> in <code>R</code>.</p>
<p><strong>see example: <code>angles-as-n-gets-large.R</code></strong></p>
<div class="example">
<p><span id="exm:unlabeled-div-279" class="example"><strong>Example 23.4  </strong></span>Let <span class="math inline">\(\mathbf{u} = \begin{pmatrix} 1 \\ 4 \\ 6 \end{pmatrix}\)</span> and <span class="math inline">\(\mathbf{v} = \begin{pmatrix} -5 \\ 2 \\ 4 \end{pmatrix}\)</span>. What is the angle between these two vectors?</p>
</div>
<div class="fold-solution">
<div class="solution">
<p><span id="unlabeled-div-69" class="solution"><em>Solution</em>. </span>The angle between the vectors <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> depends on the dot product between the two vectors and the norms (lengths) of the two vectors. The inner product of <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span> is
<span class="math display">\[
\begin{aligned}
\mathbf{u}&#39;\mathbf{v} = \begin{pmatrix} 1 &amp; 4 &amp; 6 \end{pmatrix} \begin{pmatrix} -5 \\ 2 \\ 4 \end{pmatrix} = 1*-5 +4*2 + 6*4 = 27
\end{aligned}
\]</span>
where the vector <span class="math inline">\(\mathbf{u}\)</span> has length
<span class="math display">\[
\|\mathbf{u}\| = \sqrt{u_1^2 + u_2^2 + u_3^2} = \sqrt{1^2 + 4^2 + 6^2} = \sqrt{53} = 7.2801099
\]</span>
and the vector <span class="math inline">\(\mathbf{v}\)</span> has length
<span class="math display">\[
\|\mathbf{v}\| = \sqrt{v_1^2 + v_2^2 + v_3^2} = \sqrt{-5^2 + 2^2 + 4^2} = \sqrt{45} = 6.7082039
\]</span>
Plugging these into the equation for the angle <span class="math inline">\(\theta\)</span> gives
<span class="math display">\[
\begin{aligned}
\theta = arccos \left( \frac{\mathbf{u}&#39; \mathbf{v}}{\| \mathbf{u} \| \| \mathbf{v} \|} \right) \\
= arccos \left( \frac{27}{ 7.2801099 * 6.7082039} \right) \\
= 0.984997
\end{aligned}
\]</span>
which gives an angle of <span class="math inline">\(\theta\)</span> = 0.984997 radians between the vector <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span>. In degrees, this angle is <span class="math inline">\(\theta\)</span> = 0.984997 * <span class="math inline">\(\frac{180}{\pi}\)</span> = 56.4361716 degrees.</p>
<p>In <code>R</code>, this angle can be found by finding the dot product of <span class="math inline">\(\mathbf{u}\)</span> and <span class="math inline">\(\mathbf{v}\)</span></p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="inner-product-length-and-orthogonality.html#cb354-1"></a>u &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">6</span>)</span>
<span id="cb354-2"><a href="inner-product-length-and-orthogonality.html#cb354-2"></a>v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">4</span>)</span>
<span id="cb354-3"><a href="inner-product-length-and-orthogonality.html#cb354-3"></a><span class="kw">sum</span>(u <span class="op">*</span><span class="st"> </span>v) <span class="co"># dot product of u and v</span></span></code></pre></div>
<pre><code>## [1] 27</code></pre>
<p>as well as the lengths of these two vectors</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="inner-product-length-and-orthogonality.html#cb356-1"></a><span class="kw">sqrt</span>(<span class="kw">sum</span>(u<span class="op">^</span><span class="dv">2</span>)) <span class="co"># length of u</span></span></code></pre></div>
<pre><code>## [1] 7.28011</code></pre>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="inner-product-length-and-orthogonality.html#cb358-1"></a><span class="kw">sqrt</span>(<span class="kw">sum</span>(v<span class="op">^</span><span class="dv">2</span>)) <span class="co"># length of v</span></span></code></pre></div>
<pre><code>## [1] 6.708204</code></pre>
<p>Combining these, the angle <span class="math inline">\(\theta\)</span> can be calculate in radians as</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="inner-product-length-and-orthogonality.html#cb360-1"></a>theta &lt;-<span class="st"> </span><span class="kw">acos</span>(<span class="kw">sum</span>(u <span class="op">*</span><span class="st"> </span>v) <span class="op">/</span><span class="st"> </span>(<span class="kw">sqrt</span>(<span class="kw">sum</span>(u<span class="op">^</span><span class="dv">2</span>)) <span class="op">*</span><span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">sum</span>(v<span class="op">^</span><span class="dv">2</span>))))</span>
<span id="cb360-2"><a href="inner-product-length-and-orthogonality.html#cb360-2"></a>theta</span></code></pre></div>
<pre><code>## [1] 0.984997</code></pre>
<p>and in degrees this is</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="inner-product-length-and-orthogonality.html#cb362-1"></a>theta <span class="op">*</span><span class="st"> </span><span class="dv">180</span> <span class="op">/</span><span class="st"> </span>pi</span></code></pre></div>
<pre><code>## [1] 56.43617</code></pre>
<!-- # cosine angle -->
<!-- u <- c(1, 1) -->
<!-- v <- c(-1, 2) -->
<!-- sum(u * v) -->
<!-- # euclidean norm -->
<!-- norm(u, type = '2')  -->
<!-- sqrt(sum(u^2)) -->
<!-- norm(v, type = '2')  -->
<!-- sqrt(sum(v^2)) -->
<!-- theta <- acos(sum(u * v) / (norm(u, "2") * norm(v, "2"))) -->
<!-- theta -->
<!-- theta / (pi / 2) -->
<!-- ``` -->
</div>
</div>
</div>
<div id="orthogonal-sets" class="section level2">
<h2><span class="header-section-number">23.4</span> Orthogonal sets</h2>
<p>The set of vectors <span class="math inline">\(\mathcal{S} = \{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> in <span class="math inline">\(\mathcal{R}^n\)</span> is said to be an <strong>orthogonal set</strong> if every pair of vectors is orthogonal. In other words, for all <span class="math inline">\(i \neq j\)</span>, <span class="math inline">\(\mathbf{v}_i&#39; \mathbf{v}_j = 0\)</span>. The set is called an <strong>orthonormal set</strong> if the set of vectors are orthogonal and for <span class="math inline">\(i = 1, \ldots, p\)</span>, each vector <span class="math inline">\(\mathbf{v}_i\)</span> in the set has length <span class="math inline">\(\| \mathbf{v}_i \| = 1\)</span>.</p>
<div class="example">
<p><span id="exm:unlabeled-div-280" class="example"><strong>Example 23.5  </strong></span>Show the set of vectors <span class="math inline">\(\left\{ \mathbf{v}_1 = \begin{pmatrix} 3 \\ 1 \\ 1 \end{pmatrix}, \mathbf{v}_2 = \begin{pmatrix} -\frac{1}{2} \\ -2 \\ \frac{7}{2} \end{pmatrix}, \mathbf{v}_3 = \begin{pmatrix} -1 \\ 2 \\ 1 \end{pmatrix} \right\}\)</span> is orthogonal</p>
<ul>
<li>Show these are orthogonal using <code>R</code></li>
</ul>
</div>
<p>If the set of vectors <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> are an orthogonal set, then the set of vectors <span class="math inline">\(\left\{ \frac{\mathbf{v}_1}{\|\mathbf{v}_1\|}, \ldots, \frac{\mathbf{v}_p}{\|\mathbf{v}_p\|} \right\}\)</span> is an orthonormal set. Note that for each <span class="math inline">\(i\)</span>, the length of the vector <span class="math inline">\(\frac{\mathbf{v}_i} {\|\mathbf{v}_i \|} = 1\)</span></p>
<div class="theorem">
<p><span id="thm:unlabeled-div-281" class="theorem"><strong>Theorem 23.2  </strong></span>Let the set <span class="math inline">\(\mathcal{S} = \{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> be an orthogonal set of nonzero vectors in <span class="math inline">\(\mathcal{R}^n\)</span>. Then, the set of vectors in <span class="math inline">\(\mathcal{S}\)</span> are linearly independent and therefore are a basis for the space spanned by <span class="math inline">\(\mathcal{S}\)</span>.</p>
</div>
<div class="fold-proof">
<div class="proof">
<p><span id="unlabeled-div-70" class="proof"><em>Proof</em>. </span>Assume the set of vectors <span class="math inline">\(\mathbf{v}_1, \ldots, \mathbf{v}_p\)</span> are linearly dependent. Then, there exist coefficients <span class="math inline">\(c_1, \ldots, c_p\)</span> such that
<span class="math display">\[
\begin{aligned}
\mathbf{0} &amp; = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 + \cdots + c_p \mathbf{v}_p 
\end{aligned}
\]</span>
Then, multiplying both equations on the left by <span class="math inline">\(\mathbf{v}_1&#39;\)</span> gives
<span class="math display">\[
\begin{aligned}
0 = \mathbf{v}_1&#39; \mathbf{0} &amp; = \mathbf{v}_1&#39; (c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 + \cdots + c_p \mathbf{v}_p) \\
&amp; = c_1 \mathbf{v}_1&#39; \mathbf{v}_1 + c_2  \mathbf{v}_1&#39; \mathbf{v}_2 + \cdots + c_p  \mathbf{v}_1&#39; \mathbf{v}_p \\
&amp; = c_1 \mathbf{v}_1&#39; \mathbf{v}_1 + c_2  0 + \cdots + c_p 0 \\
&amp; = c_1 \mathbf{v}_1&#39; \mathbf{v}_1
\end{aligned}
\]</span>
which is only equal to 0 when <span class="math inline">\(c_1\)</span> is equal to 0 because <span class="math inline">\(\mathbf{v}_1\)</span> is a nonzero vector. The above left multiplication could be repeated for each vector <span class="math inline">\(\mathbf{v}_i\)</span> which gives all <span class="math inline">\(c_i\)</span> must equal 0. As the only solution to the starting equation has all 0 coefficients, the set of vectors <span class="math inline">\(\mathcal{S}\)</span> must be linearly independent.</p>
</div>
</div>
<p>A set of orthogonal vectors is called an <strong>orthogonal basis</strong>.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-282" class="theorem"><strong>Theorem 23.3  </strong></span>Let <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> be an orthogonal basis of the subspace <span class="math inline">\(\mathcal{W}\)</span> of <span class="math inline">\(\mathcal{R}^n\)</span>. Then for each <span class="math inline">\(\mathbf{x} \in \mathcal{W}\)</span>, the coefficients for the linear combination of basis vectors <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> for the vector <span class="math inline">\(\mathbf{x}\)</span> are</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{x} &amp; = \frac{\mathbf{x}&#39;\mathbf{v}_1}{\mathbf{v}_1&#39;\mathbf{v}_1} \mathbf{v}_1 + \frac{\mathbf{x}&#39;\mathbf{v}_2}{\mathbf{v}_2&#39;\mathbf{v}_2} \mathbf{v}_2 + \cdots +  \frac{\mathbf{x}&#39;\mathbf{v}_p}{\mathbf{v}_p&#39;\mathbf{v}_p} \mathbf{v}_p \\
&amp; = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 + \cdots + c_p \mathbf{v}_p \\
\end{aligned}
\]</span>
where <span class="math inline">\(c_j = \frac{\mathbf{x}&#39;\mathbf{v}_j}{\mathbf{v}_j&#39;\mathbf{v}_j}\)</span>. In other words, the coordinates of the vector <span class="math inline">\(\mathbf{x}\)</span> with respect to the orthogonal basis <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> are the linear projection of the vector <span class="math inline">\(\mathbf{x}\)</span> on the respective vectors <span class="math inline">\(\mathbf{v}_j\)</span>.</p>
</div>
<div class="fold-proof">
<div class="proof">
<p><span id="unlabeled-div-71" class="proof"><em>Proof</em>. </span>The orthogonality of the basis <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> gives
<span class="math display">\[
\begin{aligned}
\mathbf{x}&#39;\mathbf{v}_j &amp; = \left(c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 + \cdots + c_p \mathbf{v}_p \right)&#39; \mathbf{v}_j \\
&amp; = c_j \mathbf{v}_j&#39; \mathbf{v}_j
\end{aligned}
\]</span>
Because we know that <span class="math inline">\(\mathbf{v}_j&#39;\mathbf{v}_j\)</span> is not zero (a vector can’t be orthogonal to itself), we can divide the above equality by <span class="math inline">\(\mathbf{v}_j&#39; \mathbf{v}_j\)</span> and solve for <span class="math inline">\(c_j = \frac{\mathbf{x}&#39;\mathbf{v}_j}{\mathbf{v}_j&#39;\mathbf{v}_j}\)</span></p>
</div>
</div>
<p>Thus, for a vector <span class="math inline">\(\mathbf{x}\)</span> in the standard basis, the coordinates of <span class="math inline">\(\mathbf{x}\)</span> with respect to an orthogonal basis can be easily calculated using dot products (rather than matrix inverses) which is an easier computation.</p>
<p>In fact, this is exactly the idea of using <strong>least squares</strong> estimation (linear regression, spline regression, etc.).</p>
</div>
<div id="orthogonal-projections" class="section level2">
<h2><span class="header-section-number">23.5</span> Orthogonal projections</h2>
<div class="definition">
<p><span id="def:unlabeled-div-283" class="definition"><strong>Definition 23.6  </strong></span>Let <span class="math inline">\(\mathbf{x}\)</span> be a vector in <span class="math inline">\(\mathcal{R}^n\)</span> and let <span class="math inline">\(\mathcal{W}\)</span> be a subspace of <span class="math inline">\(\mathcal{R}^n\)</span>. Then the vector <span class="math inline">\(\mathbf{x}\)</span> can be written as the <strong>orthogonal decomposition</strong>
<span class="math display">\[
\begin{aligned}
\mathbf{x} = \mathbf{x}_{\mathcal{W}} + \mathbf{x}_{\mathcal{W}^\perp}
\end{aligned}
\]</span>
where <span class="math inline">\(\mathbf{x}_{\mathcal{W}}\)</span> is the vector in <span class="math inline">\(\mathcal{W}\)</span> that is closest to <span class="math inline">\(\mathbf{x}\)</span> and is called the <strong>orthogonal projection of <span class="math inline">\(\mathbf{x}\)</span> onto <span class="math inline">\(\mathcal{W}\)</span></strong> and <span class="math inline">\(\mathbf{x}_{\mathcal{W}^\perp}\)</span> is the orthogonal projection of <span class="math inline">\(\mathbf{x}\)</span> onto <span class="math inline">\(\mathcal{W}^{\perp}\)</span>, the subspace <span class="math inline">\(\mathcal{W}^\perp\)</span> of <span class="math inline">\(\mathcal{R}^n\)</span> that is complementary to <span class="math inline">\(\mathcal{W}\)</span> and is called the <strong>orthogonal complement</strong>.</p>
</div>
<p><strong>Draw picture in class - W is a plane, orthogonal projection of a vector onto the plane</strong></p>
<p>This leads to the projection theorem that decomposes a vector <span class="math inline">\(\mathbf{x} \in \mathcal{R}^n\)</span> into components that are</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-284" class="theorem"><strong>Theorem 23.4  </strong></span>Let <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> be an orthogonal basis of the subspace <span class="math inline">\(\mathcal{W}\)</span> of <span class="math inline">\(\mathcal{R}^n\)</span>. Then for each <span class="math inline">\(\mathbf{x} \in \mathcal{R}^n\)</span>, the orthogonal projection of <span class="math inline">\(\mathbf{x}\)</span> onto <span class="math inline">\(\mathcal{W}\)</span> is given by
<span class="math display">\[
\begin{aligned}
\mathbf{x}_{\mathcal{W}} &amp; = \frac{\mathbf{x}&#39;\mathbf{v}_1}{\mathbf{v}_1&#39;\mathbf{v}_1} \mathbf{v}_1 + \frac{\mathbf{x}&#39;\mathbf{v}_2}{\mathbf{v}_2&#39;\mathbf{v}_2} \mathbf{v}_2 + \cdots +  \frac{\mathbf{x}&#39;\mathbf{v}_p}{\mathbf{v}_p&#39;\mathbf{v}_p} \mathbf{v}_p \\
&amp; = c_1 \mathbf{v}_1 + c_2 \mathbf{v}_2 + \cdots + c_p \mathbf{v}_p \\
\end{aligned}
\]</span>
where the coefficient <span class="math inline">\(c_j\)</span> corresponding to the vector <span class="math inline">\(\mathbf{v}_j\)</span> of the linear combination of vectors <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> is given by <span class="math inline">\(c_j = \frac{\mathbf{x}&#39;\mathbf{v}_j}{\mathbf{v}_j&#39;\mathbf{v}_j}\)</span>. In other words, the coordinates of the vector <span class="math inline">\(\mathbf{x}\)</span> with respect to the orthogonal basis <span class="math inline">\(\{ \mathbf{v}_1, \ldots, \mathbf{v}_p \}\)</span> are the linear projection of the vector <span class="math inline">\(\mathbf{x}\)</span> on the respective vectors <span class="math inline">\(\mathbf{v}_j\)</span>.</p>
</div>
<p>You might be wondering what use orthogonal projections are. In fact, linear regression (and most common regression models) use orthogonal projections to fit a line (or surface) of best fit. This leads to the important theorem that allows us to project a vector <span class="math inline">\(\mathbf{y} \in \mathcal{R}^n\)</span> onto the column space of a <span class="math inline">\(n \times p\)</span> matrix <span class="math inline">\(\mathbf{X}\)</span> (which is exactly the linear regression of <span class="math inline">\(\mathbf{y}\)</span> onto <span class="math inline">\(\mathbf{X}\)</span>).</p>
<div class="theorem">
<p><span id="thm:orthogonal-matrix-projection" class="theorem"><strong>Theorem 23.5  (Orthogonal Projection Theorem) </strong></span>Let <span class="math inline">\(\mathbf{X}\)</span> be a <span class="math inline">\(n \times p\)</span> matrix, let <span class="math inline">\(\mathcal{W} =\)</span> col(<span class="math inline">\(\mathbf{X}\)</span>), and let <span class="math inline">\(\mathbf{y}\)</span> be a vector in <span class="math inline">\(\mathcal{R}^n\)</span>. Then the matrix equation
<span class="math display">\[
\begin{aligned}
\mathbf{X}&#39;\mathbf{X} \boldsymbol{\beta} = \mathbf{X}&#39; \mathbf{y}
\end{aligned}
\]</span>
with respect to the unknown coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span> is consistent and <span class="math inline">\(\mathbf{y}_{\mathcal{W}} = \mathbf{X}\boldsymbol{\beta}\)</span> for any solution <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
</div>
<div class="fold-proof">
<div class="proof">
<p><span id="unlabeled-div-72" class="proof"><em>Proof</em>. </span>Show this in class</p>
</div>
</div>
<p>In addition, if the columns of <span class="math inline">\(\mathbf{X}\)</span> are linearly independent, then the coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span> are given by
<span class="math display">\[
\begin{aligned}
\boldsymbol{\beta} = \left( \mathbf{X}&#39;\mathbf{X} \right)^{-1} \mathbf{X}&#39; \mathbf{y}
\end{aligned}
\]</span>
which is the least squares solution to the linear regression problem. For example, let <code>X</code> and <code>y</code> be defined as below</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="inner-product-length-and-orthogonality.html#cb364-1"></a>X &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">-1</span>, <span class="dv">3</span>, <span class="dv">-4</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">-2</span>, <span class="dv">3</span>))</span>
<span id="cb364-2"><a href="inner-product-length-and-orthogonality.html#cb364-2"></a>y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">-9</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">-5</span>, <span class="dv">6</span>)</span></code></pre></div>
<p>Plotting this data shows the strong positive linear relationship</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="inner-product-length-and-orthogonality.html#cb365-1"></a><span class="co"># The first column is a basis for a constant term (the intercept)</span></span>
<span id="cb365-2"><a href="inner-product-length-and-orthogonality.html#cb365-2"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> X[, <span class="dv">2</span>], <span class="dt">y =</span> y) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb365-3"><a href="inner-product-length-and-orthogonality.html#cb365-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb365-4"><a href="inner-product-length-and-orthogonality.html#cb365-4"></a><span class="st">    </span><span class="kw">geom_point</span>()</span></code></pre></div>
<p><img src="multivariable-math_files/figure-html/example-least-squares-2-1.png" width="672" />
We can solve for the coefficients <code>beta</code> using the linear project theorem</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="inner-product-length-and-orthogonality.html#cb366-1"></a>beta &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>X) <span class="op">%*%</span><span class="st"> </span><span class="kw">t</span>(X) <span class="op">%*%</span><span class="st"> </span>y</span></code></pre></div>
<p>and using this solution, solve for the projection <span class="math inline">\(\mathbf{y}_{\mathcal{W}}\)</span> of <span class="math inline">\(\mathbf{y}\)</span> onto <span class="math inline">\(\mathbf{X}\)</span></p>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="inner-product-length-and-orthogonality.html#cb367-1"></a>y_W &lt;-<span class="st"> </span>X <span class="op">%*%</span><span class="st"> </span>beta</span></code></pre></div>
<p>Plotting the projection <span class="math inline">\(\mathbf{y}_{\mathcal{W}}\)</span> gives</p>
<div class="sourceCode" id="cb368"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb368-1"><a href="inner-product-length-and-orthogonality.html#cb368-1"></a><span class="co"># The first column is a basis for a constant term (the intercept)</span></span>
<span id="cb368-2"><a href="inner-product-length-and-orthogonality.html#cb368-2"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> X[, <span class="dv">2</span>], <span class="dt">y =</span> y, <span class="dt">y_W =</span> y_W) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb368-3"><a href="inner-product-length-and-orthogonality.html#cb368-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb368-4"><a href="inner-product-length-and-orthogonality.html#cb368-4"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb368-5"><a href="inner-product-length-and-orthogonality.html#cb368-5"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y_W))</span></code></pre></div>
<p><img src="multivariable-math_files/figure-html/example-least-squares-5-1.png" width="672" />
The complement of the project (called the <strong>residuals</strong> in statistics) is given by <span class="math inline">\(\mathbf{y}_{\mathcal{W}^\perp} = \mathbf{y} - \mathbf{y}_{\mathcal{W}}\)</span></p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="inner-product-length-and-orthogonality.html#cb369-1"></a>y_W_perp &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span>y_W</span></code></pre></div>
<p>and can be visualized as the orthogonal projection using segments</p>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="inner-product-length-and-orthogonality.html#cb370-1"></a><span class="co"># The first column is a basis for a constant term (the intercept)</span></span>
<span id="cb370-2"><a href="inner-product-length-and-orthogonality.html#cb370-2"></a><span class="kw">data.frame</span>(<span class="dt">x =</span> X[, <span class="dv">2</span>], <span class="dt">y =</span> y, <span class="dt">y_W =</span> y_W) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb370-3"><a href="inner-product-length-and-orthogonality.html#cb370-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)) <span class="op">+</span></span>
<span id="cb370-4"><a href="inner-product-length-and-orthogonality.html#cb370-4"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb370-5"><a href="inner-product-length-and-orthogonality.html#cb370-5"></a><span class="st">    </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y_W)) <span class="op">+</span></span>
<span id="cb370-6"><a href="inner-product-length-and-orthogonality.html#cb370-6"></a><span class="st">    </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y_W, <span class="dt">xend =</span> x, <span class="dt">yend =</span> y_W <span class="op">+</span><span class="st"> </span>y_W_perp), <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="multivariable-math_files/figure-html/example-least-squares-7-1.png" width="672" />
Recall that the orthogonal projection gives the “closest” vector <span class="math inline">\(\mathbf{y}_W\)</span> to <span class="math inline">\(\mathbf{y}\)</span> that is in the subspace <span class="math inline">\(\mathcal{W}\)</span> that is the span of the column space of <span class="math inline">\(\mathbf{X}\)</span>. See <a href="https://www.enchufa2.es/archives/least-squares-as-springs-the-shiny-app.html">https://www.enchufa2.es/archives/least-squares-as-springs-the-shiny-app.html</a> for an example.</p>

</div>
</div>

<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".fold-solution");
  $folds.wrapInner("<div class=\"fold-solution-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-solution-btn\">Show Solution</button>");  // add a button
  $(".fold-solution-blck").toggle();  // fold all blocks
  $(".fold-solution-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Hide Solution" ? "Show Solution" : "Hide Solution");  // if the text equals "Fold", change it to "Unfold"or else to "Fold" 
    $(this).next(".fold-solution-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>





<script type="text/javascript">
$(document).ready(function() {
  $folds = $(".fold-proof");
  $folds.wrapInner("<div class=\"fold-proof-blck\">"); // wrap a div container around content
  $folds.prepend("<button class=\"fold-proof-btn\">Show Proof</button>");  // add a button
  $(".fold-proof-blck").toggle();  // fold all blocks
  $(".fold-proof-btn").on("click", function() {  // add onClick event
    $(this).text($(this).text() === "Hide Proof" ? "Show Proof" : "Hide Proof");  // if the text equals "Fold", change it to "Unfold"or else to "Fold" 
    $(this).next(".fold-proof-blck").toggle("linear");  // "swing" is the default easing function. This can be further customized in its speed or the overall animation itself.
  })
});
</script>
            </section>

          </div>
        </div>
      </div>
<a href="diagonalization.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="graphs-and-limits.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["multivariable-math.pdf", "multivariable-math.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
